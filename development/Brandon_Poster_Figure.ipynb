{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import lineid_plot\n",
    "from ramandecompy import spectrafit\n",
    "from ramandecompy import peakidentify\n",
    "from ramandecompy import dataprep\n",
    "from ramandecompy import datavis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'Experimental_Mixture_Spectra_300C_25s.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = 502)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d64ac3a60292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Experimental_Mixture_Spectra_300C_25s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ramandecompy-1.0b0-py3.7.egg\\ramandecompy\\dataprep.py\u001b[0m in \u001b[0;36mnew_hdf5\u001b[1;34m(new_filename)\u001b[0m\n\u001b[0;32m     34\u001b[0m                         + str(type(new_filename)))\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# w- mode will create a file and fail if the file already exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mhdf5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.hdf5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mhdf5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'w-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'Experimental_Mixture_Spectra_300C_25s.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = 502)"
     ]
    }
   ],
   "source": [
    "dataprep.new_hdf5('Experimental_Mixture_Spectra_300C_25s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename = 'Experimental_Mixture_Spectra_300C_25s.hdf5'\n",
    "key = '300C/25s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.add_experiment(hdf5_filename, '../ramandecompy/tests/test_files/FA_3.6wt%_300C_25s.csv')\n",
    "# dataprep.add_experiment(hdf5_filename, '../ramandecompy/tests/test_files/FA_3.6wt%_300C_35s.csv')\n",
    "# dataprep.add_experiment(hdf5_filename, '../ramandecompy/tests/test_files/FA_3.6wt%_300C_45s.csv')\n",
    "# dataprep.add_experiment(hdf5_filename, '../ramandecompy/tests/test_files/FA_3.6wt%_300C_55s.csv')\n",
    "# dataprep.add_experiment(hdf5_filename, '../ramandecompy/tests/test_files/FA_3.6wt%_300C_65s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_list = [1270, 1350, 1385]#, 1640]\n",
    "# add_list = None\n",
    "drop_list = ['Peak_01']#, 'Peak_02']\n",
    "# drop_list = None\n",
    "\n",
    "dataprep.adjust_peaks(hdf5_filename, key, add_list, drop_list, plot_fits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdf5_calfilename = 'peakidentify_calibration_file.hdf5' #update to hdf5_calfilename\n",
    "hdf5_expfilename = 'Experimental_Mixture_Spectra_300C_25s.hdf5'\n",
    "expkey = '300C/25s'\n",
    "df = peakidentify.peak_assignment(hdf5_expfilename, expkey, hdf5_calfilename, 20,plot=True)\n",
    "plt.savefig('Adjusted_peakidentification_labeled', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_calfilename = 'peakidentify_calibration_file.hdf5'\n",
    "key1 = 'CarbonMonoxide'\n",
    "key2 = 'Hydrogen'\n",
    "key3 = 'CO2'\n",
    "key4 = 'sapphire'\n",
    "key5 = 'H2O'\n",
    "# key6 = 'Propane'\n",
    "# key7 = 'Ethane'\n",
    "# key8 = 'Acetaldehyde'\n",
    "key9 = 'FormicAcid'\n",
    "hdf5_expfilename = 'Experimental_Mixture_Spectra_300C_25s.hdf5'\n",
    "expkey = '300C/25s'\n",
    "# open .hdf5\n",
    "calhdf5 = h5py.File(hdf5_calfilename, 'r+')\n",
    "exphdf5 = h5py.File(hdf5_expfilename, 'r+')\n",
    "# extract spectra data\n",
    "residuals = np.asarray(list(exphdf5['{}/residuals'.format(expkey)]))\n",
    "unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "# extract fitted peak center values\n",
    "co_peaks = []\n",
    "H_peaks = []\n",
    "CO2_peaks = []\n",
    "sapphire_peaks = []\n",
    "H2O_peaks = []\n",
    "prop_peaks = []\n",
    "ethane_peaks = []\n",
    "alde_peaks = []\n",
    "formic_peaks = []\n",
    "unknown_peaks = []\n",
    "for _,peak in enumerate(list(calhdf5[key1])[:-3]):\n",
    "    co_peaks.append(list(calhdf5['{}/{}'.format(key1, peak)])[0][2])\n",
    "\n",
    "for _,peak in enumerate(list(calhdf5[key2])[:-3]):\n",
    "    H_peaks.append(list(calhdf5['{}/{}'.format(key2, peak)])[0][2])\n",
    "for _,peak in enumerate(list(calhdf5[key3])[:-3]):\n",
    "    CO2_peaks.append(list(calhdf5['{}/{}'.format(key3, peak)])[0][2])\n",
    "for _,peak in enumerate(list(calhdf5[key4])[:-3]):\n",
    "    sapphire_peaks.append(list(calhdf5['{}/{}'.format(key4, peak)])[0][2])\n",
    "for _,peak in enumerate(list(calhdf5[key5])[:-3]):\n",
    "    H2O_peaks.append(list(calhdf5['{}/{}'.format(key5, peak)])[0][2])\n",
    "# for _,peak in enumerate(list(calhdf5[key6])[:-3]):\n",
    "#     prop_peaks.append(list(calhdf5['{}/{}'.format(key6, peak)])[0][2])\n",
    "# for _,peak in enumerate(list(calhdf5[key7])[:-3]):\n",
    "#     ethane_peaks.append(list(calhdf5['{}/{}'.format(key7, peak)])[0][2])\n",
    "# for _,peak in enumerate(list(calhdf5[key8])[:-3]):\n",
    "#     alde_peaks.append(list(calhdf5['{}/{}'.format(key8, peak)])[0][2])\n",
    "for _,peak in enumerate(list(calhdf5[key9])[:-3]):\n",
    "    formic_peaks.append(list(calhdf5['{}/{}'.format(key9, peak)])[0][2])\n",
    "unknown_peaks = []\n",
    "for i, peak in enumerate(list(exphdf5['{}'.format(expkey)])[:-3]):\n",
    "    try:\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}'.format(expkey,\n",
    "                                                                  i+1)])[0][2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}'.format(expkey,\n",
    "                                                                 i+1)])[0][2])\n",
    "    except Exception as e:\n",
    "        #Normal peakassignment\n",
    "        print(\"\"\"Function did not receive normal peak.\n",
    "        The function continued to look for an adjusted peak.\"\"\")\n",
    "        if i < 9:\n",
    "            print(peak)\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}*'.format(expkey,\n",
    "                                                                   i+1)])[0][2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}*'.format(expkey,\n",
    "                                                                  i+1)])[0][2])\n",
    "        print('Peak_{}*'.format(i+1))\n",
    "    else:\n",
    "        pass\n",
    "unknown_x = np.asarray(unknown_x)\n",
    "unknown_y = np.asarray(unknown_y)\n",
    "known_compound_list = list(calhdf5.keys())\n",
    "precision = 10\n",
    "# known_peaks_listtest = [alde_peaks,co_peaks, CO2_peaks,ethane_peaks,formic_peaks, H_peaks, H2O_peaks, sapphire_peaks,prop_peaks]\n",
    "known_peaks_listtest = [co_peaks, CO2_peaks,formic_peaks, H_peaks, H2O_peaks, sapphire_peaks]\n",
    "known_peakstest = []\n",
    "association_matrixtest = []\n",
    "# for i, _ in enumerate(known_compound_list):\n",
    "#     for _,peak in enumerate(list(hdf5[key])[:-3]):\n",
    "#         known_peakstest.append(known_peaks_listtest[i])\n",
    "#         #print(type(known_peaks))\n",
    "#         association_matrixtest.append(compare_unknown_to_known(\n",
    "#             unknown_peakstest, known_peakstest[i], precision,\n",
    "#             hdf5_expfilename, expkey))\n",
    "\n",
    "        \n",
    "#OK, next identify all of the peaks present in the known compound set.\n",
    "    #For efficiency, we'll also compare them against the unknown in the same for loop.\n",
    "known_peaks = []\n",
    "known_peaks_list = []\n",
    "num_peaks_list = []\n",
    "association_matrix = []\n",
    "split__index_list = []\n",
    "for i, _ in enumerate(known_compound_list):\n",
    "    print(\"The peaks that we found for \"\n",
    "      + str(known_compound_list[i]) + \" are: \")\n",
    "    num_peaks_list.append(len(list(calhdf5[known_compound_list[i]])[:-3]))\n",
    "    split__index_list.append(sum(num_peaks_list))\n",
    "    for j,peak in enumerate(list(calhdf5[known_compound_list[i]])[:-3]):\n",
    "        print(list(calhdf5['{}/{}'.format(known_compound_list[i], peak)])[0][2])\n",
    "        # Need to separate known peaks to make a list of two separate lists\n",
    "        # to perform custom list split using list comprehension + zip() and split_index_list\n",
    "        known_peaks_list.append(list(calhdf5['{}/{}'.format(known_compound_list[i], peak)])[0][2])\n",
    "        result = [known_peaks_list[i : j] for i, j in zip([0] + split__index_list, split__index_list + [None])] \n",
    "    known_peaks.append(result)\n",
    "    association_matrix.append(peakidentify.compare_unknown_to_known(\n",
    "        unknown_peaks, known_peaks[i][i], precision))        \n",
    "       \n",
    "\n",
    "unknown_peak_assignments = peakidentify.peak_position_comparisons(\n",
    "    unknown_peaks,\n",
    "    known_peaks,\n",
    "    association_matrix,\n",
    "    hdf5_calfilename)\n",
    "# open .hdf5\n",
    "residuals = np.asarray(list(exphdf5['{}/residuals'.format(key)]))\n",
    "#Extract keys from files\n",
    "known_compound_list = list(calhdf5.keys())\n",
    "\n",
    "# extract spectra data\n",
    "x_data =  list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "y_data = list(exphdf5['{}/counts'.format(expkey)])\n",
    "peak_labels=[]\n",
    "for i, _ in enumerate(unknown_peak_assignments):  \n",
    "        peak_labels.append(str(unknown_peak_assignments[i]))\n",
    "frames = []\n",
    "for j, peak in enumerate(list(exphdf5['{}'.format(expkey)])[:-3]):\n",
    "    frames.append(peakidentify.add_label(hdf5_expfilename, expkey, peak, peak_labels[j]))\n",
    "\n",
    "df = pd.concat(frames,axis=1, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True,sort=True)\n",
    "df =df.T\n",
    "\n",
    "peak_labels = []\n",
    "for i, _ in enumerate(unknown_peak_assignments):\n",
    "    peak_labels.append(str(unknown_peak_assignments[i]))\n",
    "#         print(peak_labels)\n",
    "# plot spectra and peak labels\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True,\n",
    "                           gridspec_kw={'height_ratios': [3, 1]},\n",
    "                           figsize=(15, 6), dpi=300)\n",
    "# plot data\n",
    "ax1.plot(x_data, y_data, color='blue')\n",
    "ax2.plot(x_data, residuals, color='teal')\n",
    "lineid_plot.plot_line_ids(x_data, y_data, unknown_peaks,\n",
    "                      peak_labels, box_axes_space=0.30,\n",
    "                      plot_kwargs={'linewidth':1},\n",
    "                      max_iter=75, ax=ax1)\n",
    "#     fig.set_size_inches(15,5)\n",
    "# lock the scale so that additional plots do not warp the labels\n",
    "ax1.set_autoscale_on(False)\n",
    "# Titles and labels\n",
    "ax2.set_xlabel('Wavenumber ($cm^{-1}$)', fontsize=14)\n",
    "ax1.set_xlim(min(x_data), max(x_data))\n",
    "ax1.set_ylabel('Intensity (arb. units)', fontsize=14, labelpad=20)\n",
    "ax2.set_ylabel('Residuals', fontsize=14, labelpad=12)\n",
    "# scale residuals plot symmetrically about zero\n",
    "ylim = max(abs(min(residuals)), abs(max(residuals)))\n",
    "ax2.set_ylim(-ylim, ylim)\n",
    "# add grid lines to residual plot\n",
    "ax2.grid(which='major', axis='y', linestyle='-')\n",
    "# force tick labels for top plot\n",
    "ax1.tick_params(axis='both', which='both', labelsize=10, labelbottom=True)\n",
    "# add title\n",
    "ax1.set_title('{} spectra from {}'.format(key, 'Experimental_Mixture_Spectra_300C_25s'),\n",
    "          fontsize=18, pad=250)\n",
    "plt.show()\n",
    "plt.savefig('Adjusted_peakidentification_labelednew', dpi=300, bbox_inches='tight')\n",
    "#                                             association_matrix,\n",
    "#                                             hdf5_calfilename)\n",
    "# print(percentages)\n",
    "calhdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spectra and peak labels\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True,\n",
    "                           gridspec_kw={'height_ratios': [3, 1]},\n",
    "                           figsize=(15, 6), dpi=300)\n",
    "# plot data\n",
    "ax1.plot(x_data, y_data, color='blue')\n",
    "ax2.plot(x_data, residuals, color='teal')\n",
    "lineid_plot.plot_line_ids(x_data, y_data, unknown_peaks,\n",
    "                      peak_labels, box_axes_space=0.30,\n",
    "                      plot_kwargs={'linewidth':1},\n",
    "                      max_iter=75, ax=ax1)\n",
    "#     fig.set_size_inches(15,5)\n",
    "# lock the scale so that additional plots do not warp the labels\n",
    "ax1.set_autoscale_on(False)\n",
    "# Titles and labels\n",
    "ax2.set_xlabel('Wavenumber ($cm^{-1}$)', fontsize=14)\n",
    "ax1.set_xlim(min(x_data), max(x_data))\n",
    "ax1.set_ylabel('Intensity (arb. units)', fontsize=14, labelpad=20)\n",
    "ax2.set_ylabel('Residuals', fontsize=14, labelpad=12)\n",
    "# scale residuals plot symmetrically about zero\n",
    "ylim = max(abs(min(residuals)), abs(max(residuals)))\n",
    "ax2.set_ylim(-ylim, ylim)\n",
    "# add grid lines to residual plot\n",
    "ax2.grid(which='major', axis='y', linestyle='-')\n",
    "# force tick labels for top plot\n",
    "ax1.tick_params(axis='both', which='both', labelsize=10, labelbottom=True)\n",
    "# add title\n",
    "ax1.set_title('{} spectra from {}'.format(key, 'Experimental_Mixture_Spectra_300C_25s'),\n",
    "          fontsize=18, pad=250)\n",
    "plt.show()\n",
    "plt.savefig('Adjusted_peakidentification_labelednew3', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakidentify.plotting_peak_assignments(unknown_x, unknown_y, unknown_peaks, unknown_peak_assignments, hdf5_expfilename, hdf5_calfilename, expkey, peak_labels, exportlabelinput = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
