{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raman Spectroscopy Decomposition\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Once components in a mixture Raman spectra have been identified and assigned, and psudo-Voigt curve fiting has been completed the next step is to compare pure component calibration (or non-decomposing, non-reacting) area under peaks to experimental data. From this comparision one will be able to deterimine:\n",
    "1. is decomposition occuring?\n",
    "\n",
    "and if it is then: \n",
    "2. calculate the amount of molar decomposition \n",
    "\n",
    "This calculation can be completed by comparing the area value of the experimental mixture Raman spectra to the pure component calibration Raman spectra area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-step (1/2): Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#initial imports\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import lineid_plot\n",
    "from ramandecompy import spectrafit\n",
    "from ramandecompy import peakidentify\n",
    "from ramandecompy import dataprep\n",
    "from ramandecompy import dataimport\n",
    "from ramandecompy import datavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-step (2/2): Import Calibration / Pure Component Raman Spectra Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from ../ramandecompy/tests/test_files/Hydrogen_Baseline_Calibration.xlsx fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n",
      "Data from ../ramandecompy/tests/test_files/CarbonMonoxide_Baseline_Calibration.xlsx fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n",
      "Data from ../ramandecompy/tests/test_files/CO2_100wt%.csv fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n",
      "Data from ../ramandecompy/tests/test_files/water.xlsx fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n",
      "Data from ../ramandecompy/tests/test_files/sapphire.xlsx fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n",
      "Data from ../ramandecompy/tests/test_files/FormicAcid_3_6percent.xlsx fit with compound pseudo-Voigt model. Results saved to calibration_data2.hdf5.\n"
     ]
    }
   ],
   "source": [
    "dataprep.new_hdf5('calibration_data2')\n",
    "\n",
    "dataprep.add_calibration('calibration_data2.hdf5',\n",
    "                          '../ramandecompy/tests/test_files/Hydrogen_Baseline_Calibration.xlsx',\n",
    "                          label='Hydrogen')\n",
    "dataprep.add_calibration('calibration_data2.hdf5',\n",
    "                         '../ramandecompy/tests/test_files/CarbonMonoxide_Baseline_Calibration.xlsx',\n",
    "                         label='CarbonMonoxide')\n",
    "dataprep.add_calibration('calibration_data2.hdf5','../ramandecompy/tests/test_files/CO2_100wt%.csv',label='CO2')\n",
    "dataprep.add_calibration('calibration_data2.hdf5','../ramandecompy/tests/test_files/water.xlsx',label='H2O')\n",
    "dataprep.add_calibration('calibration_data2.hdf5','../ramandecompy/tests/test_files/sapphire.xlsx',label='sapphire')\n",
    "dataprep.add_calibration('calibration_data2.hdf5','../ramandecompy/tests/test_files/FormicAcid_3_6percent.xlsx',label='FormicAcid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** calibration_data2.hdf5 ****\n",
      "\u001b[1mCO2\u001b[0m\n",
      "|    Peak_01\n",
      "|    Peak_02\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n",
      "\u001b[1mCarbonMonoxide\u001b[0m\n",
      "|    Peak_01\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n",
      "\u001b[1mFormicAcid\u001b[0m\n",
      "|    Peak_01\n",
      "|    Peak_02\n",
      "|    Peak_03\n",
      "|    Peak_04\n",
      "|    Peak_05\n",
      "|    Peak_06\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n",
      "\u001b[1mH2O\u001b[0m\n",
      "|    Peak_01\n",
      "|    Peak_02\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n",
      "\u001b[1mHydrogen\u001b[0m\n",
      "|    Peak_01\n",
      "|    Peak_02\n",
      "|    Peak_03\n",
      "|    Peak_04\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n",
      "\u001b[1msapphire\u001b[0m\n",
      "|    Peak_01\n",
      "|    Peak_02\n",
      "|    Peak_03\n",
      "|    Peak_04\n",
      "|    counts\n",
      "|    residuals\n",
      "|    wavenumber\n"
     ]
    }
   ],
   "source": [
    "dataprep.view_hdf5('calibration_data2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Experimental Data Sets\n",
    "The first thing is to put experimental data into a hdf5 file (this file will end up being used to identify peaks)\n",
    "\n",
    "With multiple files in a directory/ many data sets it is usefull to loop over all files in the directory to add versus adding one by one. The code to loop came from a stackoverflow comment: `https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory`\n",
    "\n",
    "Note: A good resource for HDF5 file types in general is: `http://docs.h5py.org/en/stable/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataprep.new_hdf5('dataprep_experiment') #comment this line out once made for the first time so an error isn't given saying that the file already exists\n",
    "#directory = '/Users/elizabeth/Desktop/raman-spectra-decomp-analysis/ramandecompy/tests/test_files/' #defining directory for data\n",
    "#dataprep.view_hdf5('dataprep_experimental.hdf5')\n",
    "\n",
    "#base_dir = '../ramandecompy/tests/test_files/'\n",
    "\n",
    "#for filename in os.listdir(directory):\n",
    "#    if filename.startswith('FA_') and filename.endswith('.csv'):\n",
    "#        locationandfile = directory + filename\n",
    "#        dataprep.add_experiment('dataprep_experimental.hdf5', locationandfile)\n",
    "#        continue\n",
    "#    else:\n",
    "#        continue\n",
    "#return\n",
    "\n",
    "#FOR CALIBRATION DATA MASS ADD\n",
    "\n",
    "#dataprep.new_hdf5('dataprep_experiment') #comment this line out once made for the first time so an error isn't given saying that the file already exists\n",
    "#directory = '/Users/elizabeth/Desktop/raman-spectra-decomp-analysis/ramandecompy/tests/test_files/' #defining directory for data\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#type(filename) #checking the type (making sure is a string) for file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dataprep.view_hdf5('dataimport_ML_df-Copy1.hdf5') #making sure the loop did its job and all data is correctly imported \n",
    "#comment out this to not see the long list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define substance of interest\n",
    "The second step is to determine if the desired speciecies in the spectra is present, and if it is then if it has decomposed (decreased/changed) from the defined calibration area. \n",
    "\n",
    "At this point this will be done by the user knowing where the approximate location of the peak for the substance that is of interest. \n",
    "\n",
    "Given the user center peak wavelength location input the code will go through the calibration data and for a peak with a center at the defined location (ith some tolerance of +/- 10 cm^-1) will take the area of that curve and store it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.81690427, 19.21444133, 707.31, 12328.7434111, 38.42888266, 222.02789633, 12169.85712537)]\n",
      "<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "#getting peak information for Formic Acid \n",
    "\n",
    "data1 = h5py.File('calibration_data2.hdf5', 'r+')\n",
    "# then specify the peak\n",
    "peak_01 = list(data1['FormicAcid/Peak_01'])\n",
    "peak_01s = data1['FormicAcid/Peak_01']\n",
    "# you put list because otherwise it just saves it as a h5py.dataset or something and lists are more familiar. Then peak_01 will be a list containing the 7 elements of the Peak_01 dataset\n",
    "print(peak_01)\n",
    "\n",
    "type(peak_01)\n",
    "print(type(peak_01s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81690427, 19.21444133, 707.31, 12328.7434111, 38.42888266, 222.02789633, 12169.85712537)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_01[0] #Looking for area under the curve value for the first peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out what peak from Formic Acid to use/ are close to other observed peaks used in analysis\n",
    "For Formic Acid, prior reports of the wavenumbers of significant Raman Peaks (cm^-1) were at:\n",
    "- 712\n",
    "- 1219\n",
    "- 1400\n",
    "- 1714\n",
    "- 2943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.81690427, 19.21444133, 707.31, 12328.7434111, 38.42888266, 222.02789633, 12169.85712537)]\n"
     ]
    }
   ],
   "source": [
    "peak_01 = list(data1['FormicAcid/Peak_01'])\n",
    "print(peak_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-269eb1bc866b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpeak_02\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FormicAcid/Peak_02'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeak_02\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "peak_02 = list(data1['FormicAcid/Peak_02'])\n",
    "print(peak_02[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_03 = list(data1['FormicAcid/Peak_03'])\n",
    "print(peak_03[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_04 = list(data1['FormicAcid/Peak_04'])\n",
    "print(peak_04[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_05 = list(data1['FormicAcid/Peak_05'])\n",
    "print(peak_05[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_06 = list(data1['FormicAcid/Peak_06'])\n",
    "print(peak_06[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All peaks previously reported are identified in the calibration file within +/- 5 wavenumbers\n",
    "There is an additional peak identified at 1055, but it is hypothesized that this peak may not be easily identified from other components with similar wavenumbers and/or with the amplitude of the peak being smaller then peaks of formic acid at the other wavenumbers this could be why it isn't identifed in literature. \n",
    "\n",
    "For this example the peak occuring at 1400 cm^-1 (peak_04) will be used for molar concentration calculations **because... NEED TO FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'peak_04' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-10b7a3a91598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFA_cal_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeak_04\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFA_cal_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'peak_04' is not defined"
     ]
    }
   ],
   "source": [
    "FA_cal_area = peak_04[6]\n",
    "print(FA_cal_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define presence of substance in experimental data\n",
    "\n",
    "Then for that same center peak wavelength location input it will identify the presence of the peak (if it is there) in the experimental data and area for that peak and store it as a second variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyfinder function\n",
    "def keyfinder(hdf5_filename):\n",
    "   seconds = []\n",
    "   hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "   for _, layer_1 in enumerate(list(hdf5.keys())):\n",
    "       if isinstance(hdf5[layer_1], h5py.Group):\n",
    "   #         print('\\033[1m{}\\033[0m'.format(layer_1))\n",
    "           for _, layer_2 in enumerate(list(hdf5[layer_1].keys())):\n",
    "               if isinstance(hdf5['{}/{}'.format(layer_1, layer_2)], h5py.Group):\n",
    "   #                 print('|    \\033[1m{}\\033[0m'.format(layer_2))\n",
    "                   seconds.append('{}/{}'.format(layer_1, layer_2))\n",
    "                   for _, layer_3 in enumerate(list(hdf5['{}/{}'.format(layer_1, layer_2)])):\n",
    "                       if isinstance(hdf5['{}/{}/{}'.format(layer_1, layer_2, layer_3)],\n",
    "                                     h5py.Group):\n",
    "   #                         print('|    |    \\033[1m{}\\033[0m/...'.format(layer_3))\n",
    "                           pass\n",
    "                       else:\n",
    "                           pass\n",
    "   #                         print('|    |    {}'.format(layer_3))\n",
    "               else:\n",
    "   #                 print('|    {}'.format(layer_2))\n",
    "                   seconds.append('{}/{}'.format(layer_1, layer_2))\n",
    "       else:\n",
    "           pass\n",
    "   #         print('{}'.format(layer_1))\n",
    "   hdf5.close()\n",
    "   return seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define filenames\n",
    "hdf5_calfilename = 'calibration_data2.hdf5' #update to hdf5_calfilename\n",
    "hdf5_expfilename = 'dataimport_ML_df-Copy1.hdf5'\n",
    "\n",
    "cal_key_list = keyfinder(hdf5_calfilename)\n",
    "exp_key_list = keyfinder(hdf5_expfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CO2/Peak_01', 'CO2/Peak_02', 'CO2/counts', 'CO2/residuals', 'CO2/wavenumber', 'CarbonMonoxide/Peak_01', 'CarbonMonoxide/counts', 'CarbonMonoxide/residuals', 'CarbonMonoxide/wavenumber', 'FormicAcid/Peak_01', 'FormicAcid/Peak_02', 'FormicAcid/Peak_03', 'FormicAcid/Peak_04', 'FormicAcid/Peak_05', 'FormicAcid/Peak_06', 'FormicAcid/counts', 'FormicAcid/residuals', 'FormicAcid/wavenumber', 'H2O/Peak_01', 'H2O/Peak_02', 'H2O/counts', 'H2O/residuals', 'H2O/wavenumber', 'Hydrogen/Peak_01', 'Hydrogen/Peak_02', 'Hydrogen/Peak_03', 'Hydrogen/Peak_04', 'Hydrogen/counts', 'Hydrogen/residuals', 'Hydrogen/wavenumber', 'sapphire/Peak_01', 'sapphire/Peak_02', 'sapphire/Peak_03', 'sapphire/Peak_04', 'sapphire/counts', 'sapphire/residuals', 'sapphire/wavenumber']\n"
     ]
    }
   ],
   "source": [
    "print(cal_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['300C/25s', '300C/35s', '300C/45s', '300C/55s', '300C/65s', '320C/25s', '320C/30s', '320C/40s', '320C/50s', '320C/60s', '340C/20s', '340C/30s', '340C/40s', '340C/50s', '340C/60s', '360C/20s', '360C/30s', '360C/40s', '360C/50s', '360C/60s', '380C/15s', '380C/25s', '380C/35s', '380C/45s', '380C/55s', '390C/10s', '390C/15s', '390C/20s', '390C/25s', '390C/30s', '400C/10s', '400C/125s', '400C/15s', '400C/5s', '400C/75s', '410C/10s', '410C/125s', '410C/15s', '410C/5s', '410C/75s', '420C/10s', '420C/5s', '420C/625s', '420C/75s', '420C/875s', '430C/4s', '430C/5s', '430C/6s', '430C/7s', '430C/8s']\n"
     ]
    }
   ],
   "source": [
    "print(exp_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The peaks that we found for CO2 are: \n",
      "1280.4\n",
      "1385.3\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "The peaks that we found for CarbonMonoxide are: \n",
      "2139.9096496496495\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "The peaks that we found for FormicAcid are: \n",
      "707.31\n",
      "1055.9\n",
      "1219.5\n",
      "1400.1\n",
      "1716.7\n",
      "2940.6\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0.]\n",
      "The peaks that we found for H2O are: \n",
      "1640.6\n",
      "3194.4\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "The peaks that we found for Hydrogen are: \n",
      "355.6504104104104\n",
      "587.3333133133133\n",
      "816.0073473473473\n",
      "1035.6547747747748\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "The peaks that we found for sapphire are: \n",
      "378.71\n",
      "418.14\n",
      "575.97\n",
      "751.21\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[['Unassigned'], ['sapphire'], ['sapphire'], ['Unassigned'], ['Hydrogen', 'sapphire'], ['FormicAcid'], ['sapphire'], ['FormicAcid'], ['FormicAcid'], ['FormicAcid'], ['H2O'], ['FormicAcid'], ['CarbonMonoxide'], ['Unassigned'], ['FormicAcid'], ['H2O']]\n",
      "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '', \"['Unassigned']\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not assign tuple of length 9 to structure with 8 fields.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-294dd919688c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_key_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m    \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpeakidentify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeak_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_expfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdf5_calfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ramandecompy-1.0b0-py3.7.egg/ramandecompy/peakidentify.py\u001b[0m in \u001b[0;36mpeak_assignment\u001b[0;34m(unknownhdf5_filename, key, knownhdf5_filename, precision, exportlabelinput, plot)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munhdf5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         frames.append(pd.DataFrame(add_label(unknownhdf5_filename,\n\u001b[0;32m--> 132\u001b[0;31m                                              key, peak, peak_labels[j])))\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     df = pd.concat(frames,axis=1, join='outer', join_axes=None, ignore_index=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ramandecompy-1.0b0-py3.7.egg/ramandecompy/peakidentify.py\u001b[0m in \u001b[0;36madd_label\u001b[0;34m(hdf5_filename, key, peak, label)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;31m#     print(my_datatype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mdata_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_datatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# write new values to the blank dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not assign tuple of length 9 to structure with 8 fields."
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "df = pd.DataFrame()\n",
    "for i,key in enumerate(exp_key_list):\n",
    "   df =peakidentify.peak_assignment(hdf5_expfilename, key, hdf5_calfilename, 10, plot =False)\n",
    "   frames.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-847b636db7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m result = pd.concat(frames,axis=0, join='outer', join_axes=None, ignore_index=False,\n\u001b[1;32m      2\u001b[0m          \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          copy=True,sort=True)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "result = pd.concat(frames,axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "         keys=None, levels=None, names=None, verify_integrity=False,\n",
    "         copy=True,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key_list in 'dataimport_ML_df-Copy1.hdf5':\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Step 5: Calculate Molar Decomposition\n",
    "\n",
    "To define the molar decomposition the area of the experimental data will be divided by the calibration data's area. This value will be the molar amount of the substance at the given experimental temperature and resonance time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Plot Molar Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Molar Decomposition with Reported Literature Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
