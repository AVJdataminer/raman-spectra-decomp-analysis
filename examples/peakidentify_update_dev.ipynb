{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated PeakIdentify - Example and Functionality\n",
    "\n",
    "***\n",
    "\n",
    "This notebook walks you through the usage and functionality of the updated peakidentify function. First, the functionality will be shown by just calling the wrapper function, but subsequent examples will explore the sub-functions and explain their usage. \n",
    "\n",
    "This function was created by the Raman Noodles Dev Team, and we hope you find it to your liking. Feel free to leave issues for suggested improvments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 THINGS TO CONSIDER\n",
    "#### NEED TO IMPROVE Precision and comparing unknown known function math for precision measurements\n",
    "#### NEED TO IMPROVE Visualization and Documentation\n",
    "#### NEED TO CREATE Demo for dealing with two peaks in one place\n",
    "#### NEED TO IMPROVE Score sort function and optimize using regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 0.A: Data Input\n",
    "\n",
    "First, we'll generate the dataset that we will use to explore this functionality. This data will be downloaded from _____\n",
    "\n",
    ". In order to generate an \"unknown spectrum\" that we will be attempting to fit, ____________, and feed that in as our unknown dataset. For further explanation of the dataprep or spectrafit packages, refer to the Jupyter notebooks which present examples of their usage, also found in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from ramandecompy import spectrafit\n",
    "from ramandecompy import peakidentify\n",
    "from ramandecompy import dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a pair of known spectra from our calibration list and put it in hdf5 format with the dataprep module. See dataprep example for more details. The functions new_hdf5 and add_calibration should only be called once or else an File Already exists error will be raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'dataprep_calibration_test.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = 502)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-73e1c68e0531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataprep_calibration_test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ramandecompy-1.0b0-py3.7.egg\\ramandecompy\\dataprep.py\u001b[0m in \u001b[0;36mnew_hdf5\u001b[1;34m(new_filename)\u001b[0m\n\u001b[0;32m     13\u001b[0m                         + str(type(new_filename)))\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# w- mode will create a file and fail if the file already exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mhdf5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.hdf5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mhdf5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'w-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'dataprep_calibration_test.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = 502)"
     ]
    }
   ],
   "source": [
    "dataprep.new_hdf5('dataprep_calibration_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.view_hdf5('dataprep_calibration_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataprep.add_calibration('dataprep_calibration_test.hdf5',\n",
    "#                           '../ramandecompy/tests/test_files/Hydrogen_Baseline_Calibration.xlsx',\n",
    "#                           label='Hydrogen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataprep.add_calibration('dataprep_calibration_test.hdf5',\n",
    "#                           '../ramandecompy/tests/test_files/Methane_Baseline_Calibration.xlsx',\n",
    "#                           label='Methane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataprep.add_calibration('dataprep_calibration_test.hdf5','CO2_100wt%.csv',label='CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.view_hdf5('dataprep_calibration_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = h5py.File('dataprep_calibration_test.hdf5', 'r')\n",
    "list(test_example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_example.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotted known spectra with detected peaks\n",
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'Hydrogen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'Methane')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataprep.new_hdf5('dataprep_experiment_test')\n",
    "# dataprep.add_experiment('dataprep_experiment_test.hdf5', '../ramannoodles/tests/test_files/FA_3.6wt__300C_25s.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.view_hdf5('dataprep_experiment_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep.plot_fit('dataprep_experiment_test.hdf5', '300C/25s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Next we will open an unknown spectra from our experiments \n",
    "# FA_data = pd.read_excel('../development/FormicAcid_3percentconc_400C_5s_00000.xlsx',\n",
    "#                         header=None, names=('x', 'y'))\n",
    "# plt.figure(figsize=(16,4))\n",
    "# plt.plot(FA_data['x'], FA_data['y'], label='Formic Acid')\n",
    "# plt.legend()\n",
    "# unknown_xFA = FA_data['x']\n",
    "# unknown_yFA = FA_data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 0.B: Test Driven Development\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module used to unit test the functionality and outputs of the peakidentify.py module\n",
    "\"\"\"\n",
    "# IMPORTING MODULES\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from ramandecompy import spectrafit\n",
    "from ramandecompy import peakidentify\n",
    "from ramandecompy import dataprep\n",
    "\n",
    "def test_peak_assignment():\n",
    "    \"\"\"This function tests the operation of the peak_assignment function in peakidentify.py\"\"\"\n",
    "    #First, generate a testing dataset.\n",
    "    hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "    key = 'Methane'\n",
    "    hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "    expkey = '300C/25s'\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "    unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "    unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    known_compound_list = list(hdf5.keys())\n",
    "    precision = 0.08\n",
    "\n",
    "    #Various try statements to make sure that bad inputs are handled correctly.\n",
    "\n",
    "    try:\n",
    "        peak_assignment(hdf5_expfilename, expkey,\n",
    "                                     hdf5_filename, 'String', precision, False)\n",
    "    except TypeError:\n",
    "        print(\"An invalid known_compound_list was passed to the function, \"\n",
    "              \"and it was handled well with a TypeError.\")\n",
    "\n",
    "    try:\n",
    "        peak_assignment(hdf5_expfilename, expkey,\n",
    "                                     hdf5_filename, [1, 3, 6], precision, False)\n",
    "    except TypeError:\n",
    "        print(\"An invalid element inside known_compound_list was passed to \"\n",
    "              \"the function, and it was handled well with a TypeError.\")\n",
    "\n",
    "    try:\n",
    "        peak_assignment(hdf5_expfilename, expkey,\n",
    "                                     hdf5_filename, known_compound_list, 'precision', False)\n",
    "    except TypeError:\n",
    "        print(\"An invalid precision value was passed to the function, and \"\n",
    "              \"it was handled well with a TypeError.\")\n",
    "\n",
    "    try:\n",
    "        peak_assignment(hdf5_expfilename, expkey, hdf5_filename, known_compound_list, precision, 'False')\n",
    "        \n",
    "    except TypeError:\n",
    "        print(\"An invalid plot value was passed to the function, and it \"\n",
    "              \"was handled well with a TypeError.\")\n",
    "\n",
    "def test_compare_unknown_to_known():\n",
    "    \"\"\"This function tests the operation of the compare_unknown_to_known\n",
    "    function in peakidentify.py\"\"\"\n",
    "    #Build our test dataset.\n",
    "    hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "    key = 'Methane'\n",
    "    hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "    expkey = '300C/25s'\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "    unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "    unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    known_compound_list = list(hdf5.keys())\n",
    "    precision = 0.08\n",
    "    known_peaks = []\n",
    "    known_peaks_list = []\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        for j,peak in enumerate(list(hdf5[known_compound_list[i]])[:-2]):\n",
    "            known_peaks_list.append(list(hdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "            known_peaks.append(known_peaks_list[i])\n",
    "    unknown_peaks = []\n",
    "    for i,_ in enumerate(list(exphdf5[expkey])[:-2]):\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}'.format(expkey, i+1)])[2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}'.format(expkey, i+1)])[2])\n",
    "\n",
    "    try:\n",
    "        compare_unknown_to_known(1, known_peaks, precision, hdf5_filename, key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid unknown_peaks value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    try:\n",
    "        compare_unknown_to_known(unknown_peaks, 'known_peaks', precision, hdf5_filename, key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid known_peaks value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    try:\n",
    "        compare_unknown_to_known(unknown_peaks, known_peaks, 'precision', hdf5_filename, key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid precision value was passed to the function, and \"\n",
    "              \"was handled correctly.\")\n",
    "\n",
    "    #After testing for resilience to unexpected inputs, now ensure outputs are performing correctly\n",
    "\n",
    "    #First, make sure function is returning the list.\n",
    "    assert isinstance(compare_unknown_to_known(\n",
    "        unknown_peaks, known_peaks, precision, hdf5_filename, key), np.ndarray), (\"\"\n",
    "                                                                 \"Function is not returning list\")\n",
    "\n",
    "    #Compare one set of peaks to itself. The full association matrix should have all values = 1.\n",
    "    self_comp = np.mean(compare_unknown_to_known(known_peaks,\n",
    "                                                              known_peaks, precision,hdf5_filename, key))\n",
    "    assert self_comp == 1, (\"Peak Assignment Error. Comparison of compound \"\n",
    "                            \"against itself should find all peaks.\")\n",
    "\n",
    "    dif_comp = np.mean(compare_unknown_to_known([1, 3, 6],\n",
    "                                                             [1000, 2000, 5000], precision, hdf5_filename, key))\n",
    "    assert dif_comp == 0, (\"Peak Assignment Error. Passed values should \"\n",
    "                           \"have no matching assignments.\")\n",
    "\n",
    "def test_peak_position_comparisons():\n",
    "    \"\"\"This function tests the operation of the peak_position_comparisons\n",
    "    function in peakidentify. Said function returns a list of strings that\n",
    "    contain text assignments of each peak in the unknown spectrum.\"\"\"\n",
    "\n",
    "    #First, generate good data.\n",
    "    hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "    key2 = 'Methane'\n",
    "    key = 'Hydrogen'\n",
    "    hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "    expkey = '300C/25s'\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "    unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "    unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    known_compound_list = list(hdf5.keys())\n",
    "    unknown_peaks = []\n",
    "    precision = 0.08\n",
    "    for i,_ in enumerate(list(exphdf5[expkey])[:-2]):\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}'.format(expkey, i+1)])[2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}'.format(expkey, i+1)])[2])\n",
    "    known_peaks = []\n",
    "    known_peaks_list = [] \n",
    "    association_matrix = []\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        for j,peak in enumerate(list(hdf5[known_compound_list[i]])[:-2]):\n",
    "            known_peaks_list.append(list(hdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "        known_peaks.append(known_peaks_list)  \n",
    "        association_matrix.append(compare_unknown_to_known(\n",
    "            unknown_peaks, known_peaks[i], precision,\n",
    "            hdf5_expfilename, expkey))\n",
    "    #Then, test error handling of bad inputs for the function.\n",
    "    try:\n",
    "        peak_position_comparisons(1, known_peaks,\n",
    "                                  known_compound_list,\n",
    "                                  association_matrix,\n",
    "                                  hdf5_filename,\n",
    "                                  key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid unknown_peaks value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    try:\n",
    "        peak_position_comparisons(unknown_peaks,\n",
    "                                  'known_peaks',\n",
    "                                  known_compound_list,\n",
    "                                  association_matrix, \n",
    "                                  hdf5_filename,\n",
    "                                  key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid known_peaks value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    try:\n",
    "        peak_position_comparisons(unknown_peaks,\n",
    "                                  known_peaks,\n",
    "                                  'known_compound_list',\n",
    "                                  association_matrix,\n",
    "                                  hdf5_filename,\n",
    "                                  key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid known_compound_list value was passed to the function,\"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    try:\n",
    "        peak_position_comparisons(unknown_peaks,\n",
    "                                  known_peaks,\n",
    "                                  known_compound_list,\n",
    "                                  'association_matrix',\n",
    "                                  hdf5_filename,\n",
    "                                  key)\n",
    "    except TypeError:\n",
    "        print(\"An invalid association_matrix value was passed to the function,\"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    #Check to make sure the function is returning a list.\n",
    "    assert isinstance(peak_position_comparisons(\n",
    "        unknown_peaks, known_peaks, known_compound_list,\n",
    "        association_matrix, hdf5_filename,\n",
    "        key), list), \"The function is not returning a list.\"\n",
    "\n",
    "    #Test a call that says that no peaks have associations\n",
    "    association_matrix_0 = []\n",
    "    association_matrix_0.append(compare_unknown_to_known(known_peaks[0],\n",
    "                                                         known_peaks[1],\n",
    "                                                         0.08,\n",
    "                                                         hdf5_filename,\n",
    "                                                         key))\n",
    "    zero_output = peak_position_comparisons(known_peaks[0],\n",
    "                                            [known_peaks[1]],\n",
    "                                            [key],\n",
    "                                            association_matrix_0,\n",
    "                                            hdf5_filename,\n",
    "                                            key)[0]\n",
    "    assert zero_output[0] == 'Hydrogen', \"\"\"The function is not properly\n",
    "    handling unassigned peaks.\"\"\"\n",
    "\n",
    "    #Test the function to make sure that it has the right functionality\n",
    "    association_matrix = []\n",
    "    #Generate a matrix with all associations equal to 1\n",
    "    association_matrix.append(compare_unknown_to_known(known_peaks[0],\n",
    "                                                                    known_peaks[0],\n",
    "                                                                    0.08,\n",
    "                                                                    hdf5_filename,\n",
    "                                                                    key))\n",
    "\n",
    "    #change the middle index to 0\n",
    "    association_matrix[0][1] = 0\n",
    "    test_peak_labels = peak_position_comparisons(known_peaks[0],\n",
    "                                                              [known_peaks[0]],\n",
    "                                                              [key],\n",
    "                                                              association_matrix,\n",
    "                                                              hdf5_filename,\n",
    "                                                              key)\n",
    "    assert test_peak_labels[0][0] == 'Hydrogen', \"\"\"The funciton is\n",
    "    not correctly assigning peaks when association matrix = 1\"\"\"\n",
    "    assert test_peak_labels[1][0] == 'Unassigned', \"\"\"The function is\n",
    "    not correctly handling a lack of peak assignments\"\"\"\n",
    "    assert test_peak_labels[2][0] == 'Hydrogen', \"\"\"The funciton is\n",
    "    not correctly assigning peaks when association matrix = 1\"\"\"\n",
    "\n",
    "def test_percentage_of_peaks_found():\n",
    "    \"\"\"This function tests the operation of the\n",
    "    percentage_of_peaks_found function in peakidentify.py\"\"\"\n",
    "    #First, generate good data.\n",
    "    hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "    key = 'Hydrogen'\n",
    "    hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "    expkey = '300C/25s'\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "    # extract spectra data\n",
    "    known_x = list(hdf5['{}/wavenumber'.format(key)])\n",
    "    known_y = list(hdf5['{}/counts'.format(key)])\n",
    "    unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "    unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "    known_x = np.asarray(known_x)\n",
    "    known_y = np.asarray(known_y)\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    known_compound_list = list(hdf5.keys())\n",
    "    unknown_peaks = []\n",
    "    precision = 0.08\n",
    "    for i,_ in enumerate(list(exphdf5[expkey])[:-2]):\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}'.format(expkey, i+1)])[2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}'.format(expkey, i+1)])[2])\n",
    "    known_peaks = []\n",
    "    known_peaks_list =[]\n",
    "    association_matrix = []\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        for j,peak in enumerate(list(hdf5[known_compound_list[i]])[:-2]):\n",
    "            known_peaks_list.append(list(hdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "        known_peaks.append(known_peaks_list)    \n",
    "        association_matrix.append(compare_unknown_to_known(\n",
    "            unknown_peaks, known_peaks[i], precision,\n",
    "            hdf5_expfilename, expkey))\n",
    "\n",
    "    #Test for input error handling.\n",
    "    try:\n",
    "        percentage_of_peaks_found(1, association_matrix,\n",
    "                                  known_compound_list,\n",
    "                                  hdf5_filename)\n",
    "        \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when an int\n",
    "        was input instead of the known_peaks list\"\"\")\n",
    "\n",
    "    try:\n",
    "        percentage_of_peaks_found(known_peaks, 1,\n",
    "                                  known_compound_list,\n",
    "                                  hdf5_filename)\n",
    "        \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when an int\n",
    "        was input instead of the association matrix\"\"\")\n",
    "\n",
    "    try:\n",
    "        percentage_of_peaks_found(known_peaks,\n",
    "                                  association_matrix,\n",
    "                                  'known_compound_list',\n",
    "                                  hdf5_filename)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when a string\n",
    "        was input instead of the known_compound_list\"\"\")\n",
    "\n",
    "    try:\n",
    "        percentage_of_peaks_found(known_peaks,\n",
    "                                  association_matrix,\n",
    "                                  ['expkey'],\n",
    "                                  hdf5_filename)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the case where the compound\n",
    "        list contains something that is not a compound\"\"\")\n",
    "\n",
    "    #Test to make sure function returns a dictionary.\n",
    "    assert isinstance(percentage_of_peaks_found(\n",
    "        known_peaks,\n",
    "        association_matrix,\n",
    "        known_compound_list,\n",
    "        hdf5_filename), dict), \"\"\"The function is not\n",
    "        returning a dictionary.\"\"\"\n",
    "\n",
    "#     #Test for function output.\n",
    "    H_peaks = []\n",
    "    for _,peak in enumerate(list(hdf5[key])[:-2]):\n",
    "        H_peaks.append(list(hdf5['{}/{}'.format(key, peak)])[2])\n",
    "    H_dict_0 = percentage_of_peaks_found([H_peaks],\n",
    "                                         [[0, 0, 0,0]],\n",
    "                                         [key],\n",
    "                                         hdf5_filename)\n",
    "    assert H_dict_0[key] == 0, \"\"\"The function is not correctly\n",
    "    calculating percentages when no peaks are found\"\"\"\n",
    "\n",
    "    H_dict_1 = percentage_of_peaks_found([H_peaks],\n",
    "                                         [[1, 1, 1,1]],\n",
    "                                         [key],\n",
    "                                         hdf5_filename)\n",
    "    assert H_dict_1[key] == 100, \"\"\"The function is not correctly\n",
    "    calculating percentages when all peaks are found\"\"\"\n",
    "\n",
    "\n",
    "def test_plotting_peak_assignments():\n",
    "    \"\"\"This function tests the operation of the peak_assignment\n",
    "    function in peakidentify.py\"\"\"\n",
    "    #First, generate good data.\n",
    "    hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "    key = 'Methane'\n",
    "    hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "    expkey = '300C/25s'\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "    # extract spectra data\n",
    "    unknown_x = list(exphdf5['{}/wavenumber'.format(expkey)])\n",
    "    unknown_y = list(exphdf5['{}/counts'.format(expkey)])\n",
    "    # extract fitted peak center values\n",
    "    peak_centers = []\n",
    "    for _,peak in enumerate(list(hdf5[key])[:-2]):\n",
    "        peak_centers.append(list(hdf5['{}/{}'.format(key, peak)])[2])\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    precision = 0.08\n",
    "    unknown_peaks = []\n",
    "    #Lets identify the peaks in the unknown spectrum.\n",
    "    for i,_ in enumerate(list(exphdf5[expkey])[:-2]):\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_0{}'.format(expkey, i+1)])[2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(exphdf5['{}/Peak_{}'.format(expkey, i+1)])[2])\n",
    "\n",
    "    #OK, next identify all of the peaks present in the known compound set.\n",
    "    #For efficiency, we'll also compare them against the unknown in the same for loop.\n",
    "    known_peaks = []\n",
    "    known_peaks_list = []\n",
    "    known_compound_list = list(hdf5.keys())\n",
    "    assignment_matrix = []\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        for j,peak in enumerate(list(hdf5[known_compound_list[i]])[:-2]):\n",
    "            known_peaks_list.append(list(hdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "        known_peaks.append(known_peaks_list)    \n",
    "        assignment_matrix.append(compare_unknown_to_known(\n",
    "            unknown_peaks, known_peaks[i], precision,\n",
    "            hdf5_expfilename, expkey))\n",
    "    \n",
    "    #Ok, so that generates a full association matrix that contains everything\n",
    "    #we need to assign peaks.\n",
    "    #Now, let's go through and actually assign text to peaks.\n",
    "    unknown_peak_assignments = peak_position_comparisons(unknown_peaks,\n",
    "                                                        known_peaks,\n",
    "                                                        known_compound_list,\n",
    "                                                        assignment_matrix,\n",
    "                                                        hdf5_expfilename,\n",
    "                                                        expkey)\n",
    "    #Test for input error handling.\n",
    "    try:\n",
    "        plotting_peak_assignments(1,\n",
    "                                      unknown_y,\n",
    "                                      unknown_peaks,\n",
    "                                      unknown_peak_assignments, \n",
    "                                      hdf5_expfilename,\n",
    "                                      expkey)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error\n",
    "        when an int was input instead of the unknown_x list\"\"\")\n",
    "\n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                      3,\n",
    "                                      unknown_peaks,\n",
    "                                      unknown_peak_assignments, \n",
    "                                      hdf5_expfilename,\n",
    "                                      expkey)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when an int\n",
    "        was input instead of the unknown_y list\"\"\")\n",
    "\n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  'unknown_peaks',\n",
    "                                  unknown_peak_assignments,\n",
    "                                  hdf5_expfilename,\n",
    "                                  expkey)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when a string\n",
    "        was input instead of the unknown_peaks list\"\"\")\n",
    "\n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  unknown_peaks,\n",
    "                                  3,\n",
    "                                  hdf5_expfilename,\n",
    "                                  expkey)\n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the error when an int\n",
    "        was input instead of the unknown_peak_assignments\"\"\")\n",
    "\n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  unknown_peaks,\n",
    "                                  ['WATER', 23, 'CO'],\n",
    "                                  hdf5_expfilename,\n",
    "                                  expkey)\n",
    "                                              \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the case when an int\n",
    "        was passed in the unknown_peak_assignment list\"\"\")\n",
    "        \n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  unknown_peaks,\n",
    "                                  ['WATER', 23, 'CO'],\n",
    "                                  hdf5_expfilename,\n",
    "                                  expkey)\n",
    "                                              \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the case when an int\n",
    "        was passed in the unknown_peak_assignment list\"\"\")\n",
    "        \n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  unknown_peaks,\n",
    "                                  unknown_peak_assignments,\n",
    "                                  3,\n",
    "                                  expkey)\n",
    "                                              \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the case when an int\n",
    "        was passed in the hdf5_filename\"\"\")\n",
    "        \n",
    "    try:\n",
    "        plotting_peak_assignments(unknown_x,\n",
    "                                  unknown_y,\n",
    "                                  unknown_peaks,\n",
    "                                  unknown_peak_assignments,\n",
    "                                  hdf5_expfilename,\n",
    "                                  3)\n",
    "                                              \n",
    "    except TypeError:\n",
    "        print(\"\"\"The function correctly handled the case when an int\n",
    "        was passed in the key\"\"\")\n",
    "\n",
    "def test_peak_1d_score():\n",
    "    \"\"\"Evaluates the functionality of the peak_1D_score function\"\"\"\n",
    "    # Initialize the test arguments\n",
    "    row_i = [0, 1]\n",
    "    row_j = [2, 1]\n",
    "    rowcat = row_i + row_j\n",
    "    arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "    arraycat = np.concatenate((arraya[0], arraya[2]))\n",
    "\n",
    "    # Run Bad Function for lists\n",
    "    try:\n",
    "        testscore = peakidentify.peak_1d_score(row_i, row_j, -1)\n",
    "    except ValueError:\n",
    "        print(\"An invalid scoremax value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    # Run Bad Function for arrays\n",
    "    try:\n",
    "        arrayscore = peakidentify.peak_1d_score(arraya[0], arraya[2], -1)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"An invalid scoremax value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    # Running a good example\n",
    "    testscore = peakidentify.peak_1d_score(row_i, row_j, 1)\n",
    "    arrayscore = peakidentify.peak_1d_score(arraya[0], arraya[2], 1)\n",
    "\n",
    "    # make assertions\n",
    "    assert len(row_i) == len(row_j), 'Input lengths do not match'\n",
    "    assert len(arrayscore[0][:]) == len(arraycat), \"\"\"Output list length\n",
    "    different than concatenated lists length\"\"\"\n",
    "    for i in range(len(rowcat)):\n",
    "        assert 0 <= testscore[0][i] <= 1, 'Output value outside acceptable range'\n",
    "        assert 0 <= arrayscore[0][i] <= 1, 'Output value outside acceptable range'\n",
    "\n",
    "\n",
    "def test_score_max():\n",
    "    \"\"\"Evaluates the functionality of the score_max function\"\"\"\n",
    "    # Initialize the test arguments\n",
    "    k = 2\n",
    "    row_i = [0, 3]\n",
    "    row_j = [2, 1]\n",
    "    rowcat = row_i + row_j\n",
    "    arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "\n",
    "    arraycat = np.concatenate((arraya[0], arraya[1]))\n",
    "\n",
    "    # Run Function for lists\n",
    "    try:\n",
    "\n",
    "        maxscores = peakidentify.score_max(row_i, row_j, -1)\n",
    "\n",
    "    except ValueError:\n",
    "\n",
    "        print(\"An invalid k value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "     # Run Function for arrays\n",
    "    try:\n",
    "\n",
    "        arrmaxscores = peakidentify.score_max(arraya[0], arraya[1], -1)\n",
    "\n",
    "    except ValueError:\n",
    "\n",
    "        print(\"An invalid k value was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    # Run good examples\n",
    "    maxscores = peakidentify.score_max(row_i, row_j, k)\n",
    "    arrmaxscores = peakidentify.score_max(arraya[0], arraya[1], k)\n",
    "\n",
    "    # make assertions\n",
    "    assert len(arrmaxscores[0]) == len(arraycat), \"\"\"Output list length different\n",
    "    than concatenated lists length\"\"\"\n",
    "    for i, _ in enumerate(rowcat):\n",
    "        assert 0 <= arrmaxscores[0][i] <= 2, 'Output value outside acceptable range'\n",
    "        assert 0 <= maxscores[0][i] <= 2, 'Output value outside acceptable range'\n",
    "    for i, _ in enumerate(maxscores, 1):\n",
    "        assert maxscores[0][i-1] >= maxscores[0][-1], 'Output values are less than the max value'\n",
    "\n",
    "\n",
    "def test_score_sort():\n",
    "    \"\"\"Evaluates the functionality of the score_sort function\"\"\"\n",
    "    # Initialize the test arguments\n",
    "    row_i = [0, 1]\n",
    "    row_j = [2, 1]\n",
    "    rowcat = row_i + row_j\n",
    "    arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "    k = 2\n",
    "    arraycat = np.concatenate((arraya[0], arraya[1]))\n",
    "    # Run Previous Function to get max score normalization\n",
    "    maxscores = peakidentify.score_max(row_i, row_j, k)\n",
    "\n",
    "    # Run Function for lists\n",
    "\n",
    "    try:\n",
    "        sortedscores = peakidentify.score_sort(row_i, row_j, max(maxscores[0]))\n",
    "\n",
    "    except TypeError:\n",
    "\n",
    "        print(\"An invalid maxscores from score_max was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    # Run Function for arrays\n",
    "\n",
    "    try:\n",
    "\n",
    "        arrsortedscores = peakidentify.score_sort(arraya[0], arraya[1], max(maxscores[0]))\n",
    "\n",
    "    except TypeError:\n",
    "\n",
    "        print(\"An invalid maxscores from score_max was passed to the function, \"\n",
    "              \"and was handled correctly.\")\n",
    "\n",
    "    # Run good examples\n",
    "    sortedscores = peakidentify.score_sort(row_i, row_j, int(max(maxscores[0])))\n",
    "    arrsortedscores = peakidentify.score_sort(arraya[0],\n",
    "                                              arraya[1],\n",
    "                                              int(max(maxscores[0])))\n",
    "    # make assertions\n",
    "    assert len(arraycat) == len(arrsortedscores[0][0]), \"\"\"Output list length\n",
    "    different than concatenated lists length\"\"\"\n",
    "    assert len(rowcat) == len(sortedscores[0][0]), \"\"\"Output list length\n",
    "    different than concatenated lists length\"\"\"\n",
    "    for i, _ in enumerate(sortedscores):\n",
    "        assert sortedscores[0][0][i] <= sortedscores[0][0][i+1], \"\"\"Output values\n",
    "        is sorted from smallest to largest\"\"\"\n",
    "        assert arrsortedscores[0][0][i] <= arrsortedscores[0][0][i+1], \"\"\"Output\n",
    "        values is sorted from smallest to largest\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes in compounds from a dictionary from shoyu, and, using spectrafit,\n",
    "identifies peaks found in both the fed-in known spectra, as well as the unknown spectra\n",
    "to be analyzed. From that identification, it then classifies the peaks in the unknown\n",
    "spectra based on the fed-in known spectra.\n",
    " \"\"\"\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ramandecompy import spectrafit\n",
    "from ramandecompy import peakidentify\n",
    "from ramandecompy import dataprep\n",
    "\n",
    "\n",
    "def peak_assignment(unknownhdf5_filename, unknownkey, knownhdf5_filename,\n",
    "                    known_compound_list, precision=.08, plot=True):\n",
    "    \"\"\"This function is a wrapper function from which all classification of peaks occurs.\"\"\"\n",
    "\n",
    "    #Handling errors in inputs.\n",
    "\n",
    "    if not isinstance(known_compound_list, list):\n",
    "        raise TypeError(\"Passed value of `known_compound_list` is not a list! Instead, it is: \"\n",
    "                        + str(type(known_compound_list)))\n",
    "    # handling input errors\n",
    "    if not isinstance(knownhdf5_filename, str):\n",
    "        raise TypeError('Passed value of `knownhdf5_filename` is not a string! Instead, it is: '\n",
    "                        + str(type(knownhdf5_filename)))\n",
    "    if not knownhdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "        raise TypeError('`knownhdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "                        + knownhdf5_filename.split('/')[-1].split('.')[-1])\n",
    "    if not isinstance(unknownkey, str):\n",
    "        raise TypeError('Passed value of `unknownkey` is not a string! Instead, it is: '\n",
    "                        + str(type(unknownkey)))\n",
    "    #Now we need to check the elements within the known_compound_list to make sure they are correct.\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        if not isinstance(known_compound_list[i], str):\n",
    "            raise TypeError(\"\"\"Passed value within `known_compound_list` is not a string!\n",
    "            Instead, it is: \"\"\" + str(type(known_compound_list[i])))\n",
    "\n",
    "    if not isinstance(precision, (float, int)):\n",
    "        raise TypeError(\"\"\"Passed value of `precision` is not a float or int!\n",
    "        Instead, it is: \"\"\" + str(type(precision)))\n",
    "\n",
    "    if not isinstance(plot, bool):\n",
    "        raise TypeError(\"\"\"Passed value of `plot` is not a Boolean!\n",
    "        Instead, it is: \"\"\" + str(type(plot)))\n",
    "    # open .hdf5\n",
    "    unhdf5 = h5py.File(unknownhdf5_filename, 'r')\n",
    "    knhdf5 = h5py.File(knownhdf5_filename, 'r')\n",
    "    \n",
    "    # extract spectra data\n",
    "    known_x = list(knhdf5['{}/wavenumber'.format(known_compound_list[0])])\n",
    "    known_y = list(knhdf5['{}/counts'.format(known_compound_list[0])])\n",
    "    unknown_x = list(unhdf5['{}/wavenumber'.format(unknownkey)])\n",
    "    unknown_y = list(unhdf5['{}/counts'.format(unknownkey)])\n",
    "    known_x = np.asarray(known_x)\n",
    "    known_y = np.asarray(known_y)\n",
    "    unknown_x = np.asarray(unknown_x)\n",
    "    unknown_y = np.asarray(unknown_y)\n",
    "    #Lets identify the peaks in the unknown spectrum.\n",
    "    unknown_peaks = []\n",
    "    for i,_ in enumerate(list(unhdf5[unknownkey])[:-2]):\n",
    "        if i < 9:\n",
    "            unknown_peaks.append(list(unhdf5['{}/Peak_0{}'.format(unknownkey, i+1)])[2])\n",
    "        else:\n",
    "            unknown_peaks.append(list(unhdf5['{}/Peak_{}'.format(unknownkey, i+1)])[2])\n",
    "\n",
    "    #OK, next identify all of the peaks present in the known compound set.\n",
    "    #For efficiency, we'll also compare them against the unknown in the same for loop.\n",
    "    known_peaks = []\n",
    "    known_peaks_list = []\n",
    "    num_peaks_list = []\n",
    "    known_compound_list = list(knhdf5.keys())\n",
    "    assignment_matrix = []\n",
    "    split__index_list = []\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        print(\"The peaks that we found for \"\n",
    "          + str(known_compound_list[i]) + \" are: \")\n",
    "        num_peaks_list.append(len(list(knhdf5[known_compound_list[i]])[:-2]))\n",
    "        split__index_list.append(sum(num_peaks_list))\n",
    "        for j,peak in enumerate(list(knhdf5[known_compound_list[i]])[:-2]):\n",
    "            print(list(knhdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "            # Need to separate known peaks to make a list of two separate lists\n",
    "            # to perform custom list split using list comprehension + zip() and split_index_list\n",
    "            known_peaks_list.append(list(knhdf5['{}/{}'.format(known_compound_list[i], peak)])[2])\n",
    "            result = [known_peaks_list[i : j] for i, j in zip([0] + split__index_list, split__index_list + [None])] \n",
    "        known_peaks.append(result)\n",
    "        assignment_matrix.append(compare_unknown_to_known(\n",
    "            unknown_peaks, known_peaks[i][i], precision,\n",
    "            unknownhdf5_filename, unknownkey))\n",
    "    #Ok, so that generates a full association matrix that contains everything\n",
    "    #we need to assign peaks.\n",
    "    #Now, let's go through and actually assign text to peaks.\n",
    "    unknown_peak_assignments = peak_position_comparisons(unknown_peaks,\n",
    "                                                        known_peaks,\n",
    "                                                        known_compound_list,\n",
    "                                                        assignment_matrix,\n",
    "                                                        unknownhdf5_filename,\n",
    "                                                        unknownkey)\n",
    "    print(unknown_peak_assignments)\n",
    "\n",
    "    if plot:\n",
    "        plotting_peak_assignments(unknown_x, unknown_y, unknown_peaks,\n",
    "                                  unknown_peak_assignments,\n",
    "                                  known_compound_list,\n",
    "                                  unknownhdf5_filename,\n",
    "                                  unknownkey)\n",
    "\n",
    "    percentages = percentage_of_peaks_found(known_peaks[i],\n",
    "                                            assignment_matrix,\n",
    "                                            known_compound_list,\n",
    "                                            hdf5_filename)\n",
    "    print(percentages)\n",
    "\n",
    "    \n",
    "def compare_unknown_to_known(unknown_peaks, known_peaks, precision, hdf5_filename, key):\n",
    "    \"\"\"This function takes in peak positions for the spectrum to be\n",
    "    analyzed and a single known compound and determines if the peaks\n",
    "    found in the known compound are present in the unknown spectrum.\"\"\"\n",
    "\n",
    "    #Handling errors in inputs.\n",
    "    if not isinstance(unknown_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `combined_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(unknown_peaks)))\n",
    "\n",
    "    if not isinstance(known_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `known_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(known_peaks)))\n",
    "\n",
    "    if not isinstance(precision, (float, int)):\n",
    "        raise TypeError(\"\"\"Passed value of `precision` is not a float or int!\n",
    "        Instead, it is: \"\"\" + str(type(precision)))\n",
    "    # handling input errors\n",
    "    if not isinstance(hdf5_filename, str):\n",
    "        raise TypeError('Passed value of `hdf5_filename` is not a string! Instead, it is: '\n",
    "                        + str(type(hdf5_filename)))\n",
    "    if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "        raise TypeError('`hdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "                        + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "    if not isinstance(key, str):\n",
    "        raise TypeError('Passed value of `key` is not a string! Instead, it is: '\n",
    "                        + str(type(key)))\n",
    "\n",
    "    assignment_matrix = np.zeros(len(unknown_peaks))\n",
    "    peaks_found = 0\n",
    "    for i, _ in enumerate(unknown_peaks):\n",
    "        for j, _ in enumerate(known_peaks):\n",
    "            # instead of If, call peak_1D_score\n",
    "            if math.isclose(unknown_peaks[i], known_peaks[j],\n",
    "                            rel_tol=precision):\n",
    "                # Instead of using a 1, just input the score\n",
    "                # from the score calculator.\n",
    "                # Bigger is better.\n",
    "                # Storing only the second component in the list.\n",
    "                assignment_matrix[i] = 1\n",
    "                peaks_found += 1\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        if peaks_found == len(known_peaks):\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "    print(assignment_matrix)\n",
    "    return assignment_matrix\n",
    "\n",
    "\n",
    "def peak_position_comparisons(unknown_peaks, known_compound_peaks,\n",
    "                              known_compound_list,\n",
    "                              association_matrix,\n",
    "                              hdf5_filename,\n",
    "                              key):\n",
    "    \"\"\"This function takes in an association matrix and turns the numbers\n",
    "    given by said matrix into a text label.\"\"\"\n",
    "\n",
    "    #Handling errors in inputs.\n",
    "    if not isinstance(unknown_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `unknown_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(unknown_peaks)))\n",
    "\n",
    "    if not isinstance(known_compound_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `known_compound_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(known_compound_peaks)))\n",
    "\n",
    "    if not isinstance(known_compound_list, list):\n",
    "        raise TypeError(\"\"\"Passed value of `known_compound_list` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(known_compound_list)))\n",
    "    # handling input errors\n",
    "    if not isinstance(hdf5_filename, str):\n",
    "        raise TypeError('Passed value of `hdf5_filename` is not a string! Instead, it is: '\n",
    "                        + str(type(hdf5_filename)))\n",
    "    if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "        raise TypeError('`hdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "                        + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "    if not isinstance(key, str):\n",
    "        raise TypeError('Passed value of `key` is not a string! Instead, it is: '\n",
    "                        + str(type(key)))\n",
    "    \n",
    "    #Now we need to check the elements within the known_compound_list to make sure they are correct.\n",
    "    for i, _ in enumerate(known_compound_list):\n",
    "        if not isinstance(known_compound_list[i], str):\n",
    "            raise TypeError(\"\"\"Passed value within `known_compound_list` is not a dictionary!\n",
    "            Instead, it is: \"\"\" + str(type(known_compound_list[i])))\n",
    "\n",
    "    if not isinstance(association_matrix, list):\n",
    "        raise TypeError(\"\"\"Passed value of `association_matrix` is not a float or int!\n",
    "        Instead, it is: \"\"\" + str(type(association_matrix)))\n",
    "\n",
    "    unknown_peak_assignment = []\n",
    "    #Step through the unknown peaks to make an assignment for each unknown peak.\n",
    "\n",
    "    for i, _ in enumerate(unknown_peaks):\n",
    "        #We might be able to make a small performance improvement if we were to somehow\n",
    "        #not search the peaks we already had searched, but that seems to not be trivial.\n",
    "        position_assignment = []\n",
    "        #We'll need an outer loop that walks through all the different compound positions\n",
    "        for j, _ in enumerate(known_compound_peaks):\n",
    "            if association_matrix[j][i] == 1:\n",
    "                position_assignment.append(known_compound_list[j])\n",
    "            else:\n",
    "                pass\n",
    "        if position_assignment == []:\n",
    "            position_assignment.append(\"Unassigned\")\n",
    "        unknown_peak_assignment.append(position_assignment)\n",
    "\n",
    "    return unknown_peak_assignment\n",
    "\n",
    "\n",
    "def percentage_of_peaks_found(known_peaks, association_matrix, list_of_known_compounds, hdf5_filename):\n",
    "    \"\"\"This function takes in a list of classified peaks, and returns a percentage of\n",
    "    how many of the material's peaks are found in the unknown spectrum.\n",
    "    This can be used as a metric of confidence.\"\"\"\n",
    "\n",
    "    #Handle bad inputs\n",
    "    if not isinstance(known_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `known_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(known_peaks)))\n",
    "\n",
    "    if not isinstance(list_of_known_compounds, list):\n",
    "        raise TypeError(\"\"\"Passed value of `list_of_known_compounds` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(list_of_known_compounds)))\n",
    "    # handling input errors\n",
    "    if not isinstance(hdf5_filename, str):\n",
    "        raise TypeError('Passed value of `hdf5_filename` is not a string! Instead, it is: '\n",
    "                        + str(type(hdf5_filename)))\n",
    "    if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "        raise TypeError('`hdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "                        + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "\n",
    "    # Now we need to check the elements within the\n",
    "    # list_of_known_compounds to make sure they are correct.\n",
    "    for i, _ in enumerate(list_of_known_compounds):\n",
    "        if not isinstance(list_of_known_compounds[i], str):\n",
    "            raise TypeError(\"\"\"Passed value within `list_of_known_compounds` is not a dictionary!\n",
    "            Instead, it is: \"\"\" + str(type(list_of_known_compounds[i])))\n",
    "\n",
    "    if not isinstance(association_matrix, list):\n",
    "        raise TypeError(\"\"\"Passed value of `association_matrix` is not a float or int!\n",
    "        Instead, it is: \"\"\" + str(type(association_matrix)))\n",
    "\n",
    "    percentage_dict = {}\n",
    "    for j, _ in enumerate(list_of_known_compounds):\n",
    "        count_number = sum(association_matrix[j])\n",
    "        percentage_dict[list_of_known_compounds[j]] = float(count_number / (len(known_peaks[j]))) * 100\n",
    "\n",
    "    return percentage_dict\n",
    "\n",
    "\n",
    "def plotting_peak_assignments(unknown_x, unknown_y, unknown_peaks, unknown_peak_assignments,\n",
    "                              known_compound_list, hdf5_filename, key):\n",
    "    \"\"\"This function plots a set of unknown peaks, and plots the assigned classification given by\n",
    "    the functions within peakassignment\"\"\"\n",
    "\n",
    "    #Handling errors in inputs.\n",
    "    if not isinstance(unknown_peaks, list):\n",
    "        raise TypeError(\"\"\"Passed value of `unknown_peaks` is not a list!\n",
    "        Instead, it is: \"\"\" + str(type(unknown_peaks)))\n",
    "\n",
    "    if not isinstance(unknown_x, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `unknown_x` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(unknown_x)))\n",
    "\n",
    "    if not isinstance(unknown_y, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\" Passed value of `unknown_y` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(unknown_y)))\n",
    "    # handling input errors\n",
    "    if not isinstance(hdf5_filename, str):\n",
    "        raise TypeError('Passed value of `hdf5_filename` is not a string! Instead, it is: '\n",
    "                        + str(type(hdf5_filename)))\n",
    "    if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "        raise TypeError('`hdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "                        + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "    if not isinstance(key, str):\n",
    "        raise TypeError('Passed value of `key` is not a string! Instead, it is: '\n",
    "                        + str(type(key)))\n",
    "\n",
    "    #Now we need to check the elements within the unknown_peak_assignment\n",
    "    #to make sure they are correct.\n",
    "    for i, _ in enumerate(unknown_peak_assignments):\n",
    "        if not isinstance(unknown_peak_assignments[i], list):\n",
    "            raise TypeError(\"\"\"Passed value within `unknown_peak_assignment` is not a list!\n",
    "            Instead, it is: \"\"\" + str(type(unknown_peak_assignments[i])))\n",
    "            if not isinstance(unknown_peak_assignments[i][i], str):\n",
    "                raise TypeError(\"\"\"Passed value within `unknown_peak_assignment` is not a string!\n",
    "                Instead, it is: \"\"\" + str(type(unknown_peak_assignments[i][i])))\n",
    "    # open .hdf5\n",
    "    hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "    # extract spectra data\n",
    "    x_data = list(hdf5['{}/wavenumber'.format(key)])\n",
    "    y_data = list(hdf5['{}/counts'.format(key)])\n",
    "    colors = ['r', 'g', 'c', 'm', 'y']\n",
    "    fig = plt.figure(figsize=(10, 4), dpi=300)\n",
    "    plt.plot(unknown_x, unknown_y, color='black', label='Unknown Spectrum')\n",
    "    plt.plot(x_data, y_data, label = 'spectra data')\n",
    "    for i, _ in enumerate(unknown_peak_assignments):\n",
    "        for j, _ in enumerate(known_compound_list):           \n",
    "            if unknown_peak_assignments[i] == [known_compound_list[j]]:\n",
    "                plt.axvline(x=unknown_peaks[i], color=colors[j],\n",
    "                            label=unknown_peak_assignments[i],\n",
    "                            linestyle='--')\n",
    "            elif unknown_peak_assignments[i] == [known_compound_list[j-1],known_compound_list[j]]:\n",
    "                plt.axvline(x=unknown_peaks[i], color=colors[j-1],\n",
    "                            label=unknown_peak_assignments[i],\n",
    "                            linestyle='--')\n",
    "            else: \n",
    "                pass\n",
    "        if unknown_peak_assignments[i] == ['Unassigned']:\n",
    "            plt.axvline(x=unknown_peaks[i], color='b',\n",
    "                        label=unknown_peak_assignments[i],\n",
    "                        linestyle='--')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    plt.legend(loc=0, framealpha=1)\n",
    "    plt.xlabel('wavenumber ($cm^{-1}$)', fontsize=14)\n",
    "    plt.xlim(min(x_data), max(x_data))\n",
    "    plt.ylim(min(y_data), max(y_data))\n",
    "    plt.ylabel('counts', fontsize=14)\n",
    "    plt.title('{} spectra from {}'.format(key, hdf5_filename), fontsize=16)\n",
    "    #plt.legend(fontsize=12)\n",
    "def peak_1d_score(row_i, row_j, scoremax):\n",
    "    \"\"\"\n",
    "    Returns scores with respect to the repricoal of the\n",
    "    calculated Euclidean distance between peaks\n",
    "    #√((x1-x2)^2) in 1D\n",
    "    #√((x1-x2)^2 + (y1-y2)^2) in 2D\n",
    "\n",
    "    Parameters:\n",
    "        row_i (list like):  input list\n",
    "        row_j (list like): input list\n",
    "        scoremax (float): Euclidean reciprocal score divided by max score; default is 1\n",
    "\n",
    "    Returns:\n",
    "        scores (list): Euclidean reciprocal scores\n",
    "        peaks (tuple): peaks associated with scores\n",
    "    \"\"\"\n",
    "    # Handling errors at the input\n",
    "    if not isinstance(row_i, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_i)))\n",
    "    if not isinstance(row_j, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_j)))\n",
    "    if not isinstance(scoremax, (float, int)):\n",
    "        raise TypeError(\"\"\"Passed value of `scoremax` is not a float or int!\n",
    "        Instead, it is: \"\"\" + str(type(scoremax)))\n",
    "    if scoremax < 0:\n",
    "        raise ValueError(\"\"\"Passed value of `scoremax` is not within bounds!\"\"\")\n",
    "\n",
    "    # Initializing the variables\n",
    "    scores = []\n",
    "    peaks = []\n",
    "\n",
    "    for i, _ in enumerate(row_i):\n",
    "        for j, _ in enumerate(row_j):\n",
    "            # Calculating distances between peaks\n",
    "            distance = np.where((row_i[i] - row_j[j] > 50), np.nan,\n",
    "                                math.sqrt(sum([math.pow(row_i[i] - row_j[j], 2)])))\n",
    "            # Score for peaks less than 50 units apart\n",
    "            if 1 / (distance + 1) > .02:\n",
    "                # Dividing over the given max score\n",
    "                scores.append(((1 / (distance + 1)) / scoremax))\n",
    "                # Appends a tuple of the compared peaks\n",
    "                peaks.append((row_i[i], row_j[j]))\n",
    "            else:\n",
    "                pass\n",
    "    return scores, peaks\n",
    "\n",
    "\n",
    "def score_max(row_i, row_j, k):\n",
    "    \"\"\"\n",
    "    Returns list of scores sorted with respect to the peaks\n",
    "    related to its output max score\n",
    "\n",
    "    Parameters:\n",
    "        row_i (list like):  input list\n",
    "        row_j (list like): input list\n",
    "        k (int): input integer used to sort the scores / kth highest score\n",
    "\n",
    "    Returns:\n",
    "        maxscores (list): Euclidean reciprocal score divided by max score\n",
    "        maxpeaks (tuple): peaks associated with max scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Handling errors at the input\n",
    "    if not isinstance(row_i, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_i)))\n",
    "    if not isinstance(row_j, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_j)))\n",
    "    if not isinstance(k, int):\n",
    "        raise TypeError(\"\"\"Passed value of `k` is not an int!\n",
    "        Instead, it is: \"\"\" + str(type(k)))\n",
    "    if k < 0:\n",
    "        raise ValueError(\"\"\"Passed value of `k` is not within bounds!\"\"\")\n",
    "    try:\n",
    "        scoremax = sorted(set(peak_1d_score(row_i, row_j, 1)[0][:]))[-k]\n",
    "        maxscores, maxpeaks = peak_1d_score(row_i, row_j, scoremax)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\"\"Function did not receive a scoremax variable. The variable\n",
    "        scoremax has been reset back to 1. This is equivalent to \n",
    "        your unnormalized score.\"\"\")\n",
    "\n",
    "        maxscores, maxpeaks = peak_1d_score(row_i, row_j, scoremax=1)\n",
    "\n",
    "    return maxscores, maxpeaks\n",
    "\n",
    "\n",
    "def score_sort(row_i, row_j, k):\n",
    "    \"\"\"\n",
    "    Returns list of scores sorted\n",
    "\n",
    "    Parameters:\n",
    "        list_input (list like):  input list\n",
    "        row (list like): input list\n",
    "        k (int): input integer used to sort the scores / kth highest score\n",
    "\n",
    "    Returns:\n",
    "        sortedscores (list): sorted Euclidean distances\n",
    "    \"\"\"\n",
    "    # Handling errors at the input\n",
    "    if not isinstance(row_i, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_i)))\n",
    "    if not isinstance(row_j, (list, np.ndarray)):\n",
    "        raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "        Instead, it is: \"\"\" + str(type(row_j)))\n",
    "    if not isinstance(k, int):\n",
    "        raise TypeError(\"\"\"Passed value of `k` is not an int!\n",
    "        Instead, it is: \"\"\" + str(type(k)))\n",
    "    if k < 0:\n",
    "        raise ValueError(\"\"\"Passed value of `k` is not within bounds!\"\"\")\n",
    "\n",
    "    sortedscores = []\n",
    "    sortedscores.append(score_max(row_i, row_j, k))\n",
    "    sortedscores.sort()\n",
    "\n",
    "    return sortedscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plotting_peak_assignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_peak_1d_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage_of_peaks_found()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_peak_position_comparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compare_unknown_to_known()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_peak_assignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "key = 'Methane'\n",
    "key2 = 'Hydrogen'\n",
    "key3 = 'CO2'\n",
    "hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "expkey = '300C/25s'\n",
    "temp = '300C'\n",
    "time = '25s'\n",
    "# open .hdf5\n",
    "hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "# extract spectra data\n",
    "known_x = list(hdf5['{}/wavenumber'.format(key)])\n",
    "known_y = list(hdf5['{}/counts'.format(key)])\n",
    "\n",
    "unknown_x = list(exphdf5['{}/{}/wavenumber'.format(temp, time)])\n",
    "unknown_y = list(exphdf5['{}/{}/counts'.format(temp, time)])\n",
    "# extract fitted peak center values\n",
    "M_peaks = []\n",
    "H_peaks = []\n",
    "CO2_peaks = []\n",
    "for _,peak in enumerate(list(hdf5[key])[:-2]):\n",
    "    M_peaks.append(list(hdf5['{}/{}'.format(key, peak)])[2])\n",
    "unknown_peakstest = []\n",
    "for _,peak in enumerate(list(hdf5[key2])[:-2]):\n",
    "    H_peaks.append(list(hdf5['{}/{}'.format(key2, peak)])[2])\n",
    "for _,peak in enumerate(list(hdf5[key3])[:-2]):\n",
    "    CO2_peaks.append(list(hdf5['{}/{}'.format(key3, peak)])[2])\n",
    "for i,peak in enumerate(list(exphdf5[expkey])[:-2]):\n",
    "    if i < 9:\n",
    "        unknown_peakstest.append(list(exphdf5['{}/{}/Peak_0{}'.format(temp, time, i+1)])[2])\n",
    "    else:\n",
    "        unknown_peakstest.append(list(exphdf5['{}/{}/Peak_{}'.format(temp, time, i+1)])[2])\n",
    "known_x = np.asarray(known_x)\n",
    "known_y = np.asarray(known_y)\n",
    "unknown_x = np.asarray(unknown_x)\n",
    "unknown_y = np.asarray(unknown_y)\n",
    "known_compound_list = list(hdf5.keys())\n",
    "precision = 0.08\n",
    "known_peaks_listtest = [H_peaks, M_peaks, CO2_peaks]\n",
    "known_peakstest = []\n",
    "association_matrixtest = []\n",
    "for i, _ in enumerate(known_compound_list):\n",
    "    for _,peak in enumerate(list(hdf5[key])[:-2]):\n",
    "        known_peakstest.append(known_peaks_listtest[i])\n",
    "        #print(type(known_peaks))\n",
    "        association_matrixtest.append(compare_unknown_to_known(\n",
    "            unknown_peakstest, known_peakstest[i], precision,\n",
    "            hdf5_expfilename, expkey))\n",
    "\n",
    "unknown_peak_assignmentstest = peak_position_comparisons(\n",
    "    unknown_peakstest,\n",
    "    known_peakstest,\n",
    "    known_compound_list,\n",
    "    association_matrixtest,\n",
    "    hdf5_expfilename,\n",
    "    expkey)\n",
    "plotting_peak_assignments(unknown_x,\n",
    "                          unknown_y,\n",
    "                          unknown_peakstest,\n",
    "                          unknown_peak_assignmentstest,\n",
    "                          known_compound_list,\n",
    "                          hdf5_expfilename,\n",
    "                          expkey)\n",
    "percentages = percentage_of_peaks_found(known_peakstest,\n",
    "                                            association_matrixtest,\n",
    "                                            known_compound_list,\n",
    "                                            hdf5_filename)\n",
    "print(percentages)\n",
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'Methane')\n",
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'Hydrogen')\n",
    "dataprep.plot_fit('dataprep_calibration_test.hdf5', 'CO2')\n",
    "dataprep.plot_fit('dataprep_experiment_test.hdf5', '300C/25s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Wrapper Function - peak_assignment\n",
    "\n",
    "First, we'll generate the dataset that we will use to explore this functionality. This data will be downloaded from _____\n",
    "\n",
    ". In order to generate an \"unknown spectrum\" that we will be attempting to fit, ____________, and feed that in as our unknown dataset. For further explanation of the dataprep or spectrafit packages, refer to the Jupyter notebooks which present examples of their usage, also found in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename = 'dataprep_calibration_test.hdf5'\n",
    "key = 'Methane'\n",
    "hdf5_expfilename = 'dataprep_experiment_test.hdf5'\n",
    "expkey = '300C/25s'\n",
    "hdf5 = h5py.File(hdf5_filename, 'r')\n",
    "exphdf5 = h5py.File(hdf5_expfilename, 'r')\n",
    "peak_assignment(hdf5_expfilename, expkey, hdf5_filename, known_compound_list, precision=.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 - Individual Functions of `peakidentify.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_unknown_to_known(unknown_peakstest, H_peaks, 0.08, hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_unknown_to_known(unknown_peakstest, M_peaks, 0.08, hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_unknown_to_known(unknown_peakstest, CO2_peaks, 0.08, hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build our test data.\n",
    "association_matrix_beta = []\n",
    "known_peaks_beta = [H_peaks, M_peaks, CO2_peaks]\n",
    "association_matrix_beta.append(compare_unknown_to_known(unknown_peakstest, H_peaks, 0.08, hdf5_expfilename, expkey))\n",
    "association_matrix_beta.append(compare_unknown_to_known(unknown_peakstest, M_peaks, 0.08, hdf5_expfilename, expkey))\n",
    "association_matrix_beta.append(compare_unknown_to_known(unknown_peakstest, CO2_peaks, 0.08, hdf5_expfilename, expkey))\n",
    "print(association_matrix_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peak_position_comparisons(unknown_peakstest, known_peaks_beta, known_compound_list, association_matrix_beta, hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This function returns a list that shows all of the possible assignments for every peak, in a text format. We can see that for the unknown peak in position 0, there is a potential for that peak to have come from Hydrogen or Methane, whereas the peak in position 2, is labelled as Hydrogen. If this function does not find any possible compound for a peak, it returns a value of 'unassigned', which we will show below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peak_position_comparisons(unknown_peakstest, [H_peaks], [key2], [[0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_position_comparisons(unknown_peakstest, [M_peaks], [key], [[1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_position_comparisons(unknown_peakstest, [CO2_peaks], [key3], [[1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_peaks_found(known_peaks_beta, \n",
    "                          association_matrix_beta, \n",
    "                          known_compound_list, hdf5_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unknown_peak_assignments_beta = peak_position_comparisons(unknown_peakstest, known_peaks_beta, known_compound_list, association_matrix_beta, hdf5_expfilename, expkey)\n",
    "print(unknown_peak_assignments_beta)\n",
    "plotting_peak_assignments(unknown_x, unknown_y, unknown_peakstest, unknown_peak_assignments_beta, known_compound_list, hdf5_expfilename, expkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 Score Sort for 1D Wavenumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_1d_score(unknown_peakstest,H_peaks,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoremaxk1=score_max(unknown_peakstest,H_peaks,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=score_sort(unknown_peakstest,H_peaks,k=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_range = range(1,len(unknown_peakstest))\n",
    "for k in k_range:\n",
    "    compdf = pd.DataFrame(data=score_sort(unknown_peakstest,H_peaks,k)[0][0][:],columns=['unknown_vs_H_peak_Scores'])\n",
    "    compdf=compdf.assign(unknown_vs_H_peaks=score_sort(unknown_peakstest,H_peaks,k)[0][1][:])\n",
    "    compdf2=pd.DataFrame(data=score_sort(unknown_peakstest,M_peaks,k)[0][0][:],columns=['unknown_vs_M_peak_Scores'])\n",
    "    compdf2=compdf2.assign(unknown_vs_M_peaks=score_sort(unknown_peakstest,M_peaks,1)[0][1][:])\n",
    "    compdf3=pd.DataFrame(data=score_sort(unknown_peakstest,CO2_peaks,k)[0][0][:],columns=['unknown_vs_CO2_peak_Scores'])\n",
    "    compdf3=compdf3.assign(unknown_vs_M_peaks=score_sort(unknown_peakstest,CO2_peaks,1)[0][1][:])\n",
    "    print('This score is normalized over the #'+str(k) + ' highest score in the peak set')\n",
    "    print(compdf)\n",
    "    print(compdf2)\n",
    "    print(compdf3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of two peaks sharing one spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original peakidentify\n",
    "# \"\"\"This function takes in compounds from a dictionary from shoyu, and, using spectrafit,\n",
    "# identifies peaks found in both the fed-in known spectra, as well as the unknown spectra\n",
    "# to be analyzed. From that identification, it then classifies the peaks in the unknown\n",
    "# spectra based on the fed-in known spectra.\n",
    "#  \"\"\"\n",
    "# import math\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from ramannoodles import spectrafit\n",
    "\n",
    "\n",
    "# def peak_assignment(unknown_x, unknown_y, known_compound_list,\n",
    "#                     precision=0.03, plot=True):\n",
    "#     \"\"\"This function is a wrapper function from which all classification of peaks occurs.\"\"\"\n",
    "\n",
    "#     #Handling errors in inputs.\n",
    "#     if not isinstance(unknown_x, np.ndarray):\n",
    "#         raise TypeError(\"Passed value of `unknown_x` is not a np.ndarray! Instead, it is: \"\n",
    "#                         + str(type(unknown_x)))\n",
    "\n",
    "#     if not isinstance(unknown_y, np.ndarray):\n",
    "#         raise TypeError(\"Passed value of `unknown_y` is not a np.ndarray! Instead, it is: \"\n",
    "#                         + str(type(unknown_y)))\n",
    "\n",
    "#     if not isinstance(known_compound_list, list):\n",
    "#         raise TypeError(\"Passed value of `known_compound_list` is not a list! Instead, it is: \"\n",
    "#                         + str(type(known_compound_list)))\n",
    "\n",
    "#     #Now we need to check the elements within the known_compound_list to make sure they are correct.\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         if not isinstance(known_compound_list[i], dict):\n",
    "#             raise TypeError(\"\"\"Passed value within `known_compound_list` is not a dictionary!\n",
    "#             Instead, it is: \"\"\" + str(type(known_compound_list[i])))\n",
    "\n",
    "#     if not isinstance(precision, (float, int)):\n",
    "#         raise TypeError(\"\"\"Passed value of `precision` is not a float or int!\n",
    "#         Instead, it is: \"\"\" + str(type(precision)))\n",
    "\n",
    "#     if not isinstance(plot, bool):\n",
    "#         raise TypeError(\"\"\"Passed value of `plot` is not a Boolean!\n",
    "#         Instead, it is: \"\"\" + str(type(plot)))\n",
    "\n",
    "#     #Lets identify the peaks in the unknown spectrum.\n",
    "#     unknown_peaks = spectrafit.data_report(unknown_x, unknown_y)[0]\n",
    "\n",
    "#     #OK, next identify all of the peaks present in the known compound set.\n",
    "#     #For efficiency, we'll also compare them against the unknown in the same for loop.\n",
    "#     known_compound_peaks = []\n",
    "#     assignment_matrix = []\n",
    "\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         known_compound_peaks.append(\n",
    "#             spectrafit.compound_report(known_compound_list[i])[0])\n",
    "#         print(\"The peaks that we found for \"\n",
    "#               + str(known_compound_list[i]['title']) + \" are: \")\n",
    "#         print(known_compound_peaks[i])\n",
    "#         assignment_matrix.append(compare_unknown_to_known(unknown_peaks,\n",
    "#                                                           known_compound_peaks[i],\n",
    "#                                                           precision))\n",
    "\n",
    "#     #Ok, so that generates a full association matrix that contains everything\n",
    "#     #we need to assign peaks.\n",
    "#     #Now, let's go through and actually assign text to peaks.\n",
    "#     unknown_peak_assignments = peak_position_comparisons(unknown_peaks,\n",
    "#                                                          known_compound_peaks,\n",
    "#                                                          known_compound_list,\n",
    "#                                                          assignment_matrix)\n",
    "#     print(unknown_peak_assignments)\n",
    "\n",
    "#     if plot:\n",
    "#         plotting_peak_assignments(unknown_x, unknown_y, unknown_peaks,\n",
    "#                                   unknown_peak_assignments)\n",
    "\n",
    "#     percentages = percentage_of_peaks_found(known_compound_peaks,\n",
    "#                                             assignment_matrix,\n",
    "#                                             known_compound_list)\n",
    "#     print(percentages)\n",
    "\n",
    "\n",
    "# def compare_unknown_to_known(combined_peaks, known_peaks, precision):\n",
    "#     \"\"\"This function takes in peak positions for the spectrum to be\n",
    "#     analyzed and a single known compound and determines if the peaks\n",
    "#     found in the known compound are present in the unknown spectrum.\"\"\"\n",
    "\n",
    "#     #Handling errors in inputs.\n",
    "#     if not isinstance(combined_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `combined_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(combined_peaks)))\n",
    "\n",
    "#     if not isinstance(known_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `known_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(known_peaks)))\n",
    "\n",
    "#     if not isinstance(precision, (float, int)):\n",
    "#         raise TypeError(\"\"\"Passed value of `precision` is not a float or int!\n",
    "#         Instead, it is: \"\"\" + str(type(precision)))\n",
    "\n",
    "#     assignment_matrix = np.zeros(len(combined_peaks))\n",
    "#     peaks_found = 0\n",
    "#     for i, _ in enumerate(combined_peaks):\n",
    "#         for j, _ in enumerate(known_peaks):\n",
    "#             # instead of If, call peak_1D_score\n",
    "#             if math.isclose(combined_peaks[i], known_peaks[j],\n",
    "#                             rel_tol=precision):\n",
    "#                 # Instead of using a 1, just input the score\n",
    "#                 # from the score calculator.\n",
    "#                 # Bigger is better.\n",
    "#                 # Storing only the second component in the list.\n",
    "#                 assignment_matrix[i] = 1\n",
    "#                 peaks_found += 1\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 pass\n",
    "#         if peaks_found == len(known_peaks):\n",
    "#             continue\n",
    "#         else:\n",
    "#             pass\n",
    "#     return assignment_matrix\n",
    "\n",
    "\n",
    "# def peak_position_comparisons(unknown_peaks, known_compound_peaks,\n",
    "#                               known_compound_list,\n",
    "#                               association_matrix):\n",
    "#     \"\"\"This function takes in an association matrix and turns the numbers\n",
    "#     given by said matrix into a text label.\"\"\"\n",
    "\n",
    "#     #Handling errors in inputs.\n",
    "#     if not isinstance(unknown_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `unknown_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(unknown_peaks)))\n",
    "\n",
    "#     if not isinstance(known_compound_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `known_compound_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(known_compound_peaks)))\n",
    "\n",
    "#     if not isinstance(known_compound_list, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `known_compound_list` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(known_compound_list)))\n",
    "\n",
    "#     #Now we need to check the elements within the known_compound_list to make sure they are correct.\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         if not isinstance(known_compound_list[i], dict):\n",
    "#             raise TypeError(\"\"\"Passed value within `known_compound_list` is not a dictionary!\n",
    "#             Instead, it is: \"\"\" + str(type(known_compound_list[i])))\n",
    "\n",
    "#     if not isinstance(association_matrix, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `association_matrix` is not a float or int!\n",
    "#         Instead, it is: \"\"\" + str(type(association_matrix)))\n",
    "\n",
    "#     unknown_peak_assignment = []\n",
    "#     #Step through the unknown peaks to make an assignment for each unknown peak.\n",
    "\n",
    "#     for i, _ in enumerate(unknown_peaks):\n",
    "#         #We might be able to make a small performance improvement if we were to somehow\n",
    "#         #not search the peaks we already had searched, but that seems to not be trivial.\n",
    "#         position_assignment = []\n",
    "#         #We'll need an outer loop that walks through all the different compound positions\n",
    "#         for j, _ in enumerate(known_compound_peaks):\n",
    "#             if association_matrix[j][i] == 1:\n",
    "#                 position_assignment.append(known_compound_list[j]['title'])\n",
    "#             else:\n",
    "#                 pass\n",
    "#         if position_assignment == []:\n",
    "#             position_assignment.append(\"Unassigned\")\n",
    "#         unknown_peak_assignment.append(position_assignment)\n",
    "\n",
    "#     return unknown_peak_assignment\n",
    "\n",
    "\n",
    "# def percentage_of_peaks_found(known_peaks, association_matrix, list_of_known_compounds):\n",
    "#     \"\"\"This function takes in a list of classified peaks, and returns a percentage of\n",
    "#     how many of the material's peaks are found in the unknown spectrum.\n",
    "#     This can be used as a metric of confidence.\"\"\"\n",
    "\n",
    "#     #Handle bad inputs\n",
    "#     if not isinstance(known_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `known_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(known_peaks)))\n",
    "\n",
    "#     if not isinstance(list_of_known_compounds, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `list_of_known_compounds` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(list_of_known_compounds)))\n",
    "\n",
    "#     # Now we need to check the elements within the\n",
    "#     # list_of_known_compounds to make sure they are correct.\n",
    "#     for i, _ in enumerate(list_of_known_compounds):\n",
    "#         if not isinstance(list_of_known_compounds[i], dict):\n",
    "#             raise TypeError(\"\"\"Passed value within `list_of_known_compounds` is not a dictionary!\n",
    "#             Instead, it is: \"\"\" + str(type(list_of_known_compounds[i])))\n",
    "\n",
    "#     if not isinstance(association_matrix, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `association_matrix` is not a float or int!\n",
    "#         Instead, it is: \"\"\" + str(type(association_matrix)))\n",
    "\n",
    "#     percentage_dict = {}\n",
    "#     for i, _ in enumerate(list_of_known_compounds):\n",
    "#         count_number = sum(association_matrix[i])\n",
    "#         percentage_dict[list_of_known_compounds[i]\n",
    "#                         ['title']] = (count_number / len(known_peaks[i])) * 100\n",
    "\n",
    "#     return percentage_dict\n",
    "\n",
    "\n",
    "# def plotting_peak_assignments(unknown_x, unknown_y, unknown_peaks, unknown_peak_assignments):\n",
    "#     \"\"\"This function plots a set of unknown peaks, and plots the assigned classification given by\n",
    "#     the functions within peakassignment\"\"\"\n",
    "\n",
    "#     #Handling errors in inputs.\n",
    "#     if not isinstance(unknown_peaks, list):\n",
    "#         raise TypeError(\"\"\"Passed value of `unknown_peaks` is not a list!\n",
    "#         Instead, it is: \"\"\" + str(type(unknown_peaks)))\n",
    "\n",
    "#     if not isinstance(unknown_x, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `unknown_x` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(unknown_x)))\n",
    "\n",
    "#     if not isinstance(unknown_y, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\" Passed value of `unknown_y` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(unknown_y)))\n",
    "\n",
    "#     #Now we need to check the elements within the unknown_peak_assignment\n",
    "#     #to make sure they are correct.\n",
    "#     for i, _ in enumerate(unknown_peak_assignments):\n",
    "#         if not isinstance(unknown_peak_assignments[i], str):\n",
    "#             raise TypeError(\"\"\"Passed value within `unknown_peak_assignment` is not a string!\n",
    "#             Instead, it is: \"\"\" + str(type(unknown_peak_assignments[i])))\n",
    "\n",
    "#     colors = ['b', 'r', 'g', 'c', 'm', 'y', 'b']\n",
    "#     #fig = plt.figure(figsize=(10, 4), dpi=300)\n",
    "#     plt.plot(unknown_x, unknown_y, color='black', label='Unknown Spectrum')\n",
    "#     for i, _ in enumerate(unknown_peaks):\n",
    "#         plt.axvline(x=unknown_peaks[i], color=colors[i],\n",
    "#                     label=unknown_peak_assignments[i],\n",
    "#                     linestyle='--')\n",
    "#     plt.legend(loc=0, framealpha=1)\n",
    "#     plt.xlabel('Wavenumber (cm$^{-1}$)', fontsize=12)\n",
    "#     plt.ylabel('Counts', fontsize=12)\n",
    "#     plt.ylim(-0.01, 1.5)\n",
    "#     plt.xlim(300, 3800)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def peak_1d_score(row_i, row_j, scoremax):\n",
    "#     \"\"\"\n",
    "#     Returns scores with respect to the repricoal of the\n",
    "#     calculated Euclidean distance between peaks\n",
    "#     #√((x1-x2)^2) in 1D\n",
    "#     #√((x1-x2)^2 + (y1-y2)^2) in 2D\n",
    "\n",
    "#     Parameters:\n",
    "#         row_i (list like):  input list\n",
    "#         row_j (list like): input list\n",
    "#         scoremax (float): Euclidean reciprocal score divided by max score; default is 1\n",
    "\n",
    "#     Returns:\n",
    "#         scores (list): Euclidean reciprocal scores\n",
    "#         peaks (tuple): peaks associated with scores\n",
    "#     \"\"\"\n",
    "#     # Handling errors at the input\n",
    "#     if not isinstance(row_i, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_i)))\n",
    "#     if not isinstance(row_j, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_j)))\n",
    "#     if not isinstance(scoremax, (float, int)):\n",
    "#         raise TypeError(\"\"\"Passed value of `scoremax` is not a float or int!\n",
    "#         Instead, it is: \"\"\" + str(type(scoremax)))\n",
    "#     if scoremax < 0:\n",
    "#         raise ValueError(\"\"\"Passed value of `scoremax` is not within bounds!\"\"\")\n",
    "\n",
    "#     # Initializing the variables\n",
    "#     scores = []\n",
    "#     peaks = []\n",
    "\n",
    "#     for i, _ in enumerate(row_i):\n",
    "#         for j, _ in enumerate(row_j):\n",
    "#             # Calculating distances between peaks\n",
    "#             distance = np.where((row_i[i] - row_j[j] > 50), np.nan,\n",
    "#                                 math.sqrt(sum([math.pow(row_i[i] - row_j[j], 2)])))\n",
    "#             # Score for peaks less than 50 units apart\n",
    "#             if 1 / (distance + 1) > .02:\n",
    "#                 # Dividing over the given max score\n",
    "#                 scores.append(((1 / (distance + 1)) / scoremax))\n",
    "#                 # Appends a tuple of the compared peaks\n",
    "#                 peaks.append((row_i[i], row_j[j]))\n",
    "#             else:\n",
    "#                 pass\n",
    "#     return scores, peaks\n",
    "\n",
    "\n",
    "# def score_max(row_i, row_j, k):\n",
    "#     \"\"\"\n",
    "#     Returns list of scores sorted with respect to the peaks\n",
    "#     related to its output max score\n",
    "\n",
    "#     Parameters:\n",
    "#         row_i (list like):  input list\n",
    "#         row_j (list like): input list\n",
    "#         k (int): input integer used to sort the scores / kth highest score\n",
    "\n",
    "#     Returns:\n",
    "#         maxscores (list): Euclidean reciprocal score divided by max score\n",
    "#         maxpeaks (tuple): peaks associated with max scores\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Handling errors at the input\n",
    "#     if not isinstance(row_i, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_i)))\n",
    "#     if not isinstance(row_j, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_j)))\n",
    "#     if not isinstance(k, int):\n",
    "#         raise TypeError(\"\"\"Passed value of `k` is not an int!\n",
    "#         Instead, it is: \"\"\" + str(type(k)))\n",
    "#     if k < 0:\n",
    "#         raise ValueError(\"\"\"Passed value of `k` is not within bounds!\"\"\")\n",
    "#     try:\n",
    "#         scoremax = sorted(set(peak_1d_score(row_i, row_j, 1)[0][:]))[-k]\n",
    "#         maxscores, maxpeaks = peak_1d_score(row_i, row_j, scoremax)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(\"\"\"Function did not receive a scoremax variable. The variable\n",
    "#         scoremax has been reset back to 1.\"\"\")\n",
    "\n",
    "#         maxscores, maxpeaks = peak_1d_score(row_i, row_j, scoremax=1)\n",
    "\n",
    "#     return maxscores, maxpeaks\n",
    "\n",
    "\n",
    "# def score_sort(row_i, row_j, k):\n",
    "#     \"\"\"\n",
    "#     Returns list of scores sorted\n",
    "\n",
    "#     Parameters:\n",
    "#         list_input (list like):  input list\n",
    "#         row (list like): input list\n",
    "#         k (int): input integer used to sort the scores / kth highest score\n",
    "\n",
    "#     Returns:\n",
    "#         sortedscores (list): sorted Euclidean distances\n",
    "#     \"\"\"\n",
    "#     # Handling errors at the input\n",
    "#     if not isinstance(row_i, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_i` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_i)))\n",
    "#     if not isinstance(row_j, (list, np.ndarray)):\n",
    "#         raise TypeError(\"\"\"Passed value of `row_j` is not a list or ndarray!\n",
    "#         Instead, it is: \"\"\" + str(type(row_j)))\n",
    "#     if not isinstance(k, int):\n",
    "#         raise TypeError(\"\"\"Passed value of `k` is not an int!\n",
    "#         Instead, it is: \"\"\" + str(type(k)))\n",
    "#     if k < 0:\n",
    "#         raise ValueError(\"\"\"Passed value of `k` is not within bounds!\"\"\")\n",
    "\n",
    "#     sortedscores = []\n",
    "#     sortedscores.append(score_max(row_i, row_j, k))\n",
    "#     sortedscores.sort()\n",
    "\n",
    "#     return sortedscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove('dataprep_calibration.hdf5')\n",
    "# os.remove('dataprep_experiment.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Original test_peakidentify\n",
    "# \"\"\"\n",
    "# Module used to unit test the functionality and outputs of the peakidentify.py module\n",
    "# \"\"\"\n",
    "# # IMPORTING MODULES\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# from ramannoodles import peakidentify\n",
    "# from ramannoodles import shoyu\n",
    "# from ramannoodles import spectrafit\n",
    "\n",
    "# def test_peak_assignment():\n",
    "#     \"\"\"This function tests the operation of the peak_assignment function in peakidentify.py\"\"\"\n",
    "#     #First, generate a testing dataset.\n",
    "#     shoyu_data_dict = pickle.load(open('raman_spectra/shoyu_data_dict.p', 'rb'))\n",
    "#     compound_1 = shoyu_data_dict['WATER']\n",
    "#     compound_2 = shoyu_data_dict['CARBON MONOXIDE']\n",
    "#     compound_3 = shoyu_data_dict['CARBON DIOXIDE']\n",
    "#     unknown_x, unknown_y = shoyu.combine_spectra(compound_1, compound_2, plot=False)\n",
    "#     unknown_x = np.asarray(unknown_x)\n",
    "#     unknown_y = np.asarray(unknown_y)\n",
    "#     known_compound_list = [compound_1, compound_2, compound_3]\n",
    "#     precision = 0.03\n",
    "\n",
    "#     #Various try statements to make sure that bad inputs are handled correctly.\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(1, unknown_y, known_compound_list, precision, False)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid unknown_x was passed to the function, and it was\"\n",
    "#               \" handled well with a TypeError.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(unknown_x, 2, known_compound_list, precision, False)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid unknown_y was passed to the function, and it was \"\n",
    "#               \"handled well with a TypeError.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(unknown_x, unknown_y, 'string', precision, False)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid known_compound_list was passed to the function, \"\n",
    "#               \"and it was handled well with a TypeError.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(unknown_x, unknown_y, [1, 3, 6], precision, False)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid element inside known_compound_list was passed to \"\n",
    "#               \"the function, and it was handled well with a TypeError.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(unknown_x, unknown_y, known_compound_list, 'precision', False)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid precision value was passed to the function, and \"\n",
    "#               \"it was handled well with a TypeError.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_assignment(1, unknown_y, known_compound_list, precision, 'False')\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid plot value was passed to the function, and it \"\n",
    "#               \"was handled well with a TypeError.\")\n",
    "\n",
    "# def test_compare_unknown_to_known():\n",
    "#     \"\"\"This function tests the operation of the compare_unknown_to_known\n",
    "#     function in peakidentify.py\"\"\"\n",
    "#     #Build our test dataset.\n",
    "#     shoyu_data_dict = pickle.load(open('raman_spectra/shoyu_data_dict.p', 'rb'))\n",
    "#     compound_1 = shoyu_data_dict['WATER']\n",
    "#     compound_2 = shoyu_data_dict['CARBON MONOXIDE']\n",
    "#     compound_3 = shoyu_data_dict['CARBON DIOXIDE']\n",
    "#     unknown_x, unknown_y = shoyu.combine_spectra(compound_1, compound_2, plot=False)\n",
    "#     unknown_x = np.asarray(unknown_x)\n",
    "#     unknown_y = np.asarray(unknown_y)\n",
    "#     known_compound_list = [compound_1, compound_2, compound_3]\n",
    "#     precision = 0.03\n",
    "#     known_peaks = []\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         known_peaks.append(spectrafit.compound_report(known_compound_list[i])[0])\n",
    "#     unknown_peaks = spectrafit.data_report(unknown_x, unknown_y)[0]\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.compare_unknown_to_known(1, known_peaks[0], precision)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid unknown_peaks value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.compare_unknown_to_known(unknown_peaks, 'known_peaks', precision)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid known_peaks value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.compare_unknown_to_known(unknown_peaks, known_peaks[0], 'precision')\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid precision value was passed to the function, and \"\n",
    "#               \"was handled correctly.\")\n",
    "\n",
    "#     #After testing for resilience to unexpected inputs, now ensure outputs are performing correctly\n",
    "\n",
    "#     #First, make sure function is returning the list.\n",
    "#     assert isinstance(peakidentify.compare_unknown_to_known(\n",
    "#         unknown_peaks, known_peaks[0], precision), np.ndarray), (\"\"\n",
    "#                                                                  \"Function is not returning list\")\n",
    "\n",
    "#     #Compare one set of peaks to itself. The full association matrix should have all values = 1.\n",
    "#     self_comp = np.mean(peakidentify.compare_unknown_to_known(known_peaks[0],\n",
    "#                                                               known_peaks[0], precision))\n",
    "#     assert self_comp == 1, (\"Peak Assignment Error. Comparison of compound \"\n",
    "#                             \"against itself should find all peaks.\")\n",
    "\n",
    "#     dif_comp = np.mean(peakidentify.compare_unknown_to_known([1, 3, 6],\n",
    "#                                                              [1000, 2000, 5000], precision))\n",
    "#     assert dif_comp == 0, (\"Peak Assignment Error. Passed values should \"\n",
    "#                            \"have no matching assignments.\")\n",
    "\n",
    "# def test_peak_position_comparisons():\n",
    "#     \"\"\"This function tests the operation of the peak_position_comparisons\n",
    "#     function in peakidentify. Said function returns a list of strings that\n",
    "#     contain text assignments of each peak in the unknown spectrum.\"\"\"\n",
    "\n",
    "#     #First, generate good data.\n",
    "#     shoyu_data_dict = pickle.load(open('raman_spectra/shoyu_data_dict.p', 'rb'))\n",
    "#     compound_1 = shoyu_data_dict['WATER']\n",
    "#     compound_2 = shoyu_data_dict['CARBON MONOXIDE']\n",
    "#     compound_3 = shoyu_data_dict['CARBON DIOXIDE']\n",
    "#     unknown_x, unknown_y = shoyu.combine_spectra(compound_1, compound_2, plot=False)\n",
    "#     unknown_x = np.asarray(unknown_x)\n",
    "#     unknown_y = np.asarray(unknown_y)\n",
    "#     known_compound_list = [compound_1, compound_2, compound_3]\n",
    "#     unknown_peaks = spectrafit.data_report(unknown_x, unknown_y)[0]\n",
    "#     known_peaks = []\n",
    "#     association_matrix = []\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         known_peaks.append(spectrafit.compound_report(known_compound_list[i])[0])\n",
    "#         association_matrix.append(peakidentify.compare_unknown_to_known(\n",
    "#             unknown_peaks, known_peaks[i], 0.03))\n",
    "\n",
    "#     #Then, test error handling of bad inputs for the function.\n",
    "#     try:\n",
    "#         peakidentify.peak_position_comparisons(1, known_peaks,\n",
    "#                                                known_compound_list,\n",
    "#                                                association_matrix)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid unknown_peaks value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_position_comparisons(unknown_peaks,\n",
    "#                                                'known_peaks',\n",
    "#                                                known_compound_list,\n",
    "#                                                association_matrix)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid known_peaks value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_position_comparisons(unknown_peaks,\n",
    "#                                                known_peaks,\n",
    "#                                                'known_compound_list',\n",
    "#                                                association_matrix)\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid known_compound_list value was passed to the function,\"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.peak_position_comparisons(unknown_peaks,\n",
    "#                                                known_peaks,\n",
    "#                                                known_compound_list,\n",
    "#                                                'association_matrix')\n",
    "#     except TypeError:\n",
    "#         print(\"An invalid association_matrix value was passed to the function,\"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     #Check to make sure the function is returning a list.\n",
    "#     assert isinstance(peakidentify.peak_position_comparisons(\n",
    "#         unknown_peaks, known_peaks, known_compound_list,\n",
    "#         association_matrix), list), \"The function is not returning a list.\"\n",
    "\n",
    "#     #Test a call that says that no peaks have associations\n",
    "#     association_matrix_0 = []\n",
    "#     association_matrix_0.append(peakidentify.compare_unknown_to_known(known_peaks[0],\n",
    "#                                                                       known_peaks[1],\n",
    "#                                                                       0.03))\n",
    "#     zero_output = peakidentify.peak_position_comparisons(known_peaks[0],\n",
    "#                                                          [known_peaks[1]],\n",
    "#                                                          [compound_1],\n",
    "#                                                          association_matrix_0)[0]\n",
    "#     assert zero_output[0] == 'Unassigned', \"\"\"The function is not properly\n",
    "#     handling unassigned peaks.\"\"\"\n",
    "\n",
    "#     #Test the function to make sure that it has the right functionality\n",
    "#     association_matrix = []\n",
    "#     #Generate a matrix with all associations equal to 1\n",
    "#     association_matrix.append(peakidentify.compare_unknown_to_known(known_peaks[0],\n",
    "#                                                                     known_peaks[0],\n",
    "#                                                                     0.03))\n",
    "#     #change the middle index to 0\n",
    "#     association_matrix[0][1] = 0\n",
    "#     test_peak_labels = peakidentify.peak_position_comparisons(known_peaks[0],\n",
    "#                                                               [known_peaks[0]],\n",
    "#                                                               [compound_1],\n",
    "#                                                               association_matrix)\n",
    "#     assert test_peak_labels[0][0] == 'WATER', \"\"\"The function is\n",
    "#     not correctly assigning peaks when association matrix = 1\"\"\"\n",
    "#     assert test_peak_labels[1][0] == 'Unassigned', \"\"\"The function is\n",
    "#     not correctly handling a lack of peak assignments\"\"\"\n",
    "#     assert test_peak_labels[2][0] == 'WATER', \"\"\"The funciton is\n",
    "#     not correctly assigning peaks when association matrix = 1\"\"\"\n",
    "\n",
    "# def test_percentage_of_peaks_found():\n",
    "#     \"\"\"This function tests the operation of the\n",
    "#     percentage_of_peaks_found function in peakidentify.py\"\"\"\n",
    "#     #First, generate good data.\n",
    "#     shoyu_data_dict = pickle.load(open('raman_spectra/shoyu_data_dict.p', 'rb'))\n",
    "#     compound_1 = shoyu_data_dict['WATER']\n",
    "#     compound_2 = shoyu_data_dict['CARBON MONOXIDE']\n",
    "#     compound_3 = shoyu_data_dict['CARBON DIOXIDE']\n",
    "#     unknown_x, unknown_y = shoyu.combine_spectra(compound_1, compound_2, plot=False)\n",
    "#     unknown_x = np.asarray(unknown_x)\n",
    "#     unknown_y = np.asarray(unknown_y)\n",
    "#     known_compound_list = [compound_1, compound_2, compound_3]\n",
    "#     unknown_peaks = spectrafit.data_report(unknown_x, unknown_y)[0]\n",
    "#     known_peaks = []\n",
    "#     association_matrix = []\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         known_peaks.append(spectrafit.compound_report(known_compound_list[i])[0])\n",
    "#         association_matrix.append(peakidentify.compare_unknown_to_known(unknown_peaks,\n",
    "#                                                                         known_peaks[i],\n",
    "#                                                                         0.03))\n",
    "\n",
    "#     #Test for input error handling.\n",
    "#     try:\n",
    "#         peakidentify.percentage_of_peaks_found(1, association_matrix, known_compound_list)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when an int\n",
    "#         was input instead of the known_peaks list\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.percentage_of_peaks_found(known_peaks, 1, known_compound_list)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when an int\n",
    "#         was input instead of the association matrix\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.percentage_of_peaks_found(known_peaks,\n",
    "#                                                association_matrix,\n",
    "#                                                'known_compound_list')\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when a string\n",
    "#         was input instead of the known_compound_list\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.percentage_of_peaks_found(known_peaks,\n",
    "#                                                association_matrix,\n",
    "#                                                [compound_1,\n",
    "#                                                 compound_2,\n",
    "#                                                 'compound_3'])\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the case where the compound\n",
    "#         list contains something that is not a compound\"\"\")\n",
    "\n",
    "#     #Test to make sure function returns a dictionary.\n",
    "#     assert isinstance(peakidentify.percentage_of_peaks_found(\n",
    "#         known_peaks,\n",
    "#         association_matrix,\n",
    "#         known_compound_list), dict), \"\"\"The function is not\n",
    "#         returning a dictionary.\"\"\"\n",
    "\n",
    "#     #Test for function output.\n",
    "#     water_peaks = spectrafit.compound_report(compound_1)[0]\n",
    "#     water_dict_0 = peakidentify.percentage_of_peaks_found([water_peaks],\n",
    "#                                                           [[0, 0, 0]],\n",
    "#                                                           [compound_1])\n",
    "#     assert water_dict_0['WATER'] == 0, \"\"\"The function is not correctly\n",
    "#     calculating percentages when no peaks are found\"\"\"\n",
    "\n",
    "#     water_dict_1 = peakidentify.percentage_of_peaks_found([water_peaks],\n",
    "#                                                           [[1, 1, 1]],\n",
    "#                                                           [compound_1])\n",
    "#     assert water_dict_1['WATER'] == 100, \"\"\"The function is not correctly\n",
    "#     calculating percentages when all peaks are found\"\"\"\n",
    "\n",
    "\n",
    "# def test_plotting_peak_assignments():\n",
    "#     \"\"\"This function tests the operation of the peak_assignment\n",
    "#     function in peakidentify.py\"\"\"\n",
    "#     #First, generate good data.\n",
    "#     shoyu_data_dict = pickle.load(open('raman_spectra/shoyu_data_dict.p', 'rb'))\n",
    "#     compound_1 = shoyu_data_dict['WATER']\n",
    "#     compound_2 = shoyu_data_dict['CARBON MONOXIDE']\n",
    "#     compound_3 = shoyu_data_dict['CARBON DIOXIDE']\n",
    "#     unknown_x, unknown_y = shoyu.combine_spectra(compound_1, compound_2, plot=False)\n",
    "#     unknown_x = np.asarray(unknown_x)\n",
    "#     unknown_y = np.asarray(unknown_y)\n",
    "#     known_compound_list = [compound_1, compound_2, compound_3]\n",
    "#     precision = 0.03\n",
    "#     unknown_peaks = spectrafit.data_report(unknown_x, unknown_y)[0]\n",
    "#     known_peaks = []\n",
    "#     association_matrix = []\n",
    "#     for i, _ in enumerate(known_compound_list):\n",
    "#         known_peaks.append(spectrafit.compound_report(known_compound_list[i])[0])\n",
    "#         association_matrix.append(peakidentify.compare_unknown_to_known(\n",
    "#             unknown_peaks, known_peaks[i], precision))\n",
    "#     unknown_peak_assignments = peakidentify.peak_position_comparisons(\n",
    "#         unknown_peaks,\n",
    "#         known_peaks,\n",
    "#         known_compound_list,\n",
    "#         association_matrix)\n",
    "\n",
    "#     #Test for input error handling.\n",
    "#     try:\n",
    "#         peakidentify.plotting_peak_assignments(1,\n",
    "#                                                unknown_y,\n",
    "#                                                unknown_peaks,\n",
    "#                                                unknown_peak_assignments)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error\n",
    "#         when an int was input instead of the unknown_x list\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.plotting_peak_assignments(unknown_x,\n",
    "#                                                3,\n",
    "#                                                unknown_peaks,\n",
    "#                                                unknown_peak_assignments)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when an int\n",
    "#         was input instead of the unknown_y list\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.plotting_peak_assignments(unknown_x,\n",
    "#                                                unknown_y,\n",
    "#                                                'unknown_peaks',\n",
    "#                                                unknown_peak_assignments)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when a string\n",
    "#         was input instead of the unknown_peaks list\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.plotting_peak_assignments(unknown_x,\n",
    "#                                                unknown_y,\n",
    "#                                                unknown_peaks,\n",
    "#                                                3)\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the error when an int\n",
    "#         was input instead of the unknown_peak_assignments\"\"\")\n",
    "\n",
    "#     try:\n",
    "#         peakidentify.plotting_peak_assignments(unknown_x,\n",
    "#                                                unknown_y,\n",
    "#                                                unknown_peaks,\n",
    "#                                                ['WATER', 23, 'CO'])\n",
    "#     except TypeError:\n",
    "#         print(\"\"\"The function correctly handled the case when an int\n",
    "#         was passed in the unknown_peak_assignment list\"\"\")\n",
    "\n",
    "# def test_peak_1d_score():\n",
    "#     \"\"\"Evaluates the functionality of the peak_1D_score function\"\"\"\n",
    "#     # Initialize the test arguments\n",
    "#     row_i = [0, 1]\n",
    "#     row_j = [2, 1]\n",
    "#     rowcat = row_i + row_j\n",
    "#     arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "#     arraycat = np.concatenate((arraya[0], arraya[2]))\n",
    "\n",
    "#     # Run Bad Function for lists\n",
    "#     try:\n",
    "#         testscore = peakidentify.peak_1d_score(row_i, row_j, -1)\n",
    "#     except ValueError:\n",
    "#         print(\"An invalid scoremax value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     # Run Bad Function for arrays\n",
    "#     try:\n",
    "#         arrayscore = peakidentify.peak_1d_score(arraya[0], arraya[2], -1)\n",
    "\n",
    "#     except ValueError:\n",
    "#         print(\"An invalid scoremax value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     # Running a good example\n",
    "#     testscore = peakidentify.peak_1d_score(row_i, row_j, 1)\n",
    "#     arrayscore = peakidentify.peak_1d_score(arraya[0], arraya[2], 1)\n",
    "\n",
    "#     # make assertions\n",
    "#     assert len(row_i) == len(row_j), 'Input lengths do not match'\n",
    "#     assert len(arrayscore[0][:]) == len(arraycat), \"\"\"Output list length\n",
    "#     different than concatenated lists length\"\"\"\n",
    "#     for i in range(len(rowcat)):\n",
    "#         assert 0 <= testscore[0][i] <= 1, 'Output value outside acceptable range'\n",
    "#         assert 0 <= arrayscore[0][i] <= 1, 'Output value outside acceptable range'\n",
    "\n",
    "\n",
    "# def test_score_max():\n",
    "#     \"\"\"Evaluates the functionality of the score_max function\"\"\"\n",
    "#     # Initialize the test arguments\n",
    "#     k = 2\n",
    "#     row_i = [0, 3]\n",
    "#     row_j = [2, 1]\n",
    "#     rowcat = row_i + row_j\n",
    "#     arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "\n",
    "#     arraycat = np.concatenate((arraya[0], arraya[1]))\n",
    "\n",
    "#     # Run Function for lists\n",
    "#     try:\n",
    "\n",
    "#         maxscores = peakidentify.score_max(row_i, row_j, -1)\n",
    "\n",
    "#     except ValueError:\n",
    "\n",
    "#         print(\"An invalid k value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#      # Run Function for arrays\n",
    "#     try:\n",
    "\n",
    "#         arrmaxscores = peakidentify.score_max(arraya[0], arraya[1], -1)\n",
    "\n",
    "#     except ValueError:\n",
    "\n",
    "#         print(\"An invalid k value was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     # Run good examples\n",
    "#     maxscores = peakidentify.score_max(row_i, row_j, k)\n",
    "#     arrmaxscores = peakidentify.score_max(arraya[0], arraya[1], k)\n",
    "\n",
    "#     # make assertions\n",
    "#     assert len(arrmaxscores[0]) == len(arraycat), \"\"\"Output list length different\n",
    "#     than concatenated lists length\"\"\"\n",
    "#     for i, _ in enumerate(rowcat):\n",
    "#         assert 0 <= arrmaxscores[0][i] <= 2, 'Output value outside acceptable range'\n",
    "#         assert 0 <= maxscores[0][i] <= 2, 'Output value outside acceptable range'\n",
    "#     for i, _ in enumerate(maxscores, 1):\n",
    "#         assert maxscores[0][i-1] >= maxscores[0][-1], 'Output values are less than the max value'\n",
    "\n",
    "\n",
    "# def test_score_sort():\n",
    "#     \"\"\"Evaluates the functionality of the score_sort function\"\"\"\n",
    "#     # Initialize the test arguments\n",
    "#     row_i = [0, 1]\n",
    "#     row_j = [2, 1]\n",
    "#     rowcat = row_i + row_j\n",
    "#     arraya = np.array([[0, 1], [2, 1], [0, 3]])\n",
    "#     k = 2\n",
    "#     arraycat = np.concatenate((arraya[0], arraya[1]))\n",
    "#     # Run Previous Function to get max score normalization\n",
    "#     maxscores = peakidentify.score_max(row_i, row_j, k)\n",
    "\n",
    "#     # Run Function for lists\n",
    "\n",
    "#     try:\n",
    "#         sortedscores = peakidentify.score_sort(row_i, row_j, max(maxscores[0]))\n",
    "\n",
    "#     except TypeError:\n",
    "\n",
    "#         print(\"An invalid maxscores from score_max was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     # Run Function for arrays\n",
    "\n",
    "#     try:\n",
    "\n",
    "#         arrsortedscores = peakidentify.score_sort(arraya[0], arraya[1], max(maxscores[0]))\n",
    "\n",
    "#     except TypeError:\n",
    "\n",
    "#         print(\"An invalid maxscores from score_max was passed to the function, \"\n",
    "#               \"and was handled correctly.\")\n",
    "\n",
    "#     # Run good examples\n",
    "#     sortedscores = peakidentify.score_sort(row_i, row_j, int(max(maxscores[0])))\n",
    "#     arrsortedscores = peakidentify.score_sort(arraya[0],\n",
    "#                                               arraya[1],\n",
    "#                                               int(max(maxscores[0])))\n",
    "#     # make assertions\n",
    "#     assert len(arraycat) == len(arrsortedscores[0][0]), \"\"\"Output list length\n",
    "#     different than concatenated lists length\"\"\"\n",
    "#     assert len(rowcat) == len(sortedscores[0][0]), \"\"\"Output list length\n",
    "#     different than concatenated lists length\"\"\"\n",
    "#     for i, _ in enumerate(sortedscores):\n",
    "#         assert sortedscores[0][0][i] <= sortedscores[0][0][i+1], \"\"\"Output values\n",
    "#         is sorted from smallest to largest\"\"\"\n",
    "#         assert arrsortedscores[0][0][i] <= arrsortedscores[0][0][i+1], \"\"\"Output\n",
    "#         values is sorted from smallest to largest\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW HDF5 file\n",
    "# # handling input errors\n",
    "# if not isinstance(new_filename, str):\n",
    "#     raise TypeError('Passed value of `filename` is not a string! Instead, it is: '\n",
    "#                     + str(type(new_filename)))\n",
    "# # w- mode will create a file and fail if the file already exists\n",
    "# hdf5 = h5py.File('{}.hdf5'.format(new_filename), 'w-')\n",
    "# hdf5.close()\n",
    "\n",
    "# # CALIBRATION\n",
    "# # handling input errors\n",
    "# if not isinstance(hdf5_filename, str):\n",
    "#     raise TypeError('Passed value of `cal_filename` is not a string! Instead, it is: '\n",
    "#                     + str(type(hdf5_filename)))\n",
    "# if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "#     raise TypeError('`cal_filename` is not type = .hdf5! Instead, it is: '\n",
    "#                     + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "# if not isinstance(data_filename, str):\n",
    "#     raise TypeError('Passed value of `data_filename` is not a string! Instead, it is: '\n",
    "#                     + str(type(data_filename)))\n",
    "# # r+ is read/write mode and will fail if the file does not exist\n",
    "# cal_file = h5py.File(hdf5_filename, 'r+')\n",
    "# data = pd.read_excel(data_filename, header=None, names=('x', 'y'))\n",
    "# if data_filename.split('.')[-1] == 'xlsx':\n",
    "#     data = pd.read_excel(data_filename, header=None, names=('x', 'y'))\n",
    "# elif data_filename.split('.')[-1] == 'csv':\n",
    "#     data = pd.read_csv(data_filename, header=None, names=('x', 'y'))\n",
    "# else:\n",
    "#     print('data file type not recognized')\n",
    "# # ensure that the data is listed from smallest wavenumber first\n",
    "# if data['x'][:1].values > data['x'][-1:].values:\n",
    "#     data = data.iloc[::-1]\n",
    "#     data.reset_index(inplace=True, drop=True)\n",
    "# else:\n",
    "#     pass\n",
    "# # peak detection and data fitting\n",
    "# fit_result = spectrafit.fit_data(data['x'].values, data['y'].values)\n",
    "# # write data to .hdf5 using custom label if provided\n",
    "# if label is not None:\n",
    "#     cal_file['{}/wavenumber'.format(label)] = data['x']\n",
    "#     cal_file['{}/counts'.format(label)] = data['y']\n",
    "#     for i, _ in enumerate(fit_result):\n",
    "#         cal_file['{}/Peak_{}'.format(label, i+1)] = fit_result[i]\n",
    "# else:\n",
    "#     label = (data_filename.split('/')[-1]).split('.')[0]\n",
    "#     cal_file['{}/wavenumber'.format(label)] = data['x']\n",
    "#     cal_file['{}/counts'.format(label)] = data['y']\n",
    "#     for i, _ in enumerate(fit_result):\n",
    "#         cal_file['{}/Peak_{}'.format(label, i+1)] = fit_result[i]\n",
    "# cal_file.close()\n",
    "\n",
    "\n",
    "# #def add_experiment(hdf5_filename, exp_filename):\n",
    "# \"\"\"docstring\"\"\"\n",
    "# # handling input errors\n",
    "# if not isinstance(hdf5_filename, str):\n",
    "#     raise TypeError('Passed value of `hdf5_filename` is not a string! Instead, it is: '\n",
    "#                     + str(type(hdf5_filename)))\n",
    "# if not hdf5_filename.split('/')[-1].split('.')[-1] == 'hdf5':\n",
    "#     raise TypeError('`hdf5_filename` is not type = .hdf5! Instead, it is: '\n",
    "#                     + hdf5_filename.split('/')[-1].split('.')[-1])\n",
    "# if not isinstance(exp_filename, str):\n",
    "#     raise TypeError('Passed value of `data_filename` is not a string! Instead, it is: '\n",
    "#                     + str(type(exp_filename)))\n",
    "# # r+ is read/write mode and will fail if the file does not exist\n",
    "# exp_file = h5py.File(hdf5_filename, 'r+')\n",
    "# if exp_filename.split('.')[-1] == 'xlsx':\n",
    "#     data = pd.read_excel(exp_filename, header=None, names=('x', 'y'))\n",
    "# elif exp_filename.split('.')[-1] == 'csv':\n",
    "#     data = pd.read_csv(exp_filename, header=None, names=('x', 'y'))\n",
    "# else:\n",
    "#     print('data file type not recognized')\n",
    "# # ensure that the data is listed from smallest wavenumber first\n",
    "# if data['x'][:1].values > data['x'][-1:].values:\n",
    "#     data = data.iloc[::-1]\n",
    "#     data.reset_index(inplace=True, drop=True)\n",
    "# else:\n",
    "#     pass\n",
    "# # peak detection and data fitting\n",
    "# fit_result = spectrafit.fit_data(data['x'].values, data['y'].values)\n",
    "# # extract experimental parameters from filename\n",
    "# specs = exp_filename.split('/')[-1].split('.')[:-1]\n",
    "# if len(specs) > 1:\n",
    "#     spec = ''\n",
    "#     for _,element in enumerate(specs):\n",
    "#         spec = str(spec+element)\n",
    "#     specs = spec\n",
    "# specs = specs.split('_')\n",
    "# specs\n",
    "# time = specs[-1]\n",
    "# temp = specs[-2]\n",
    "# # write data to .hdf5\n",
    "# exp_file['{}/{}/wavenumber'.format(temp, time)] = data['x']\n",
    "# exp_file['{}/{}/counts'.format(temp, time)] = data['y']\n",
    "# for i, _ in enumerate(fit_result):\n",
    "#     if i < 9:\n",
    "#         exp_file['{}/{}/Peak_0{}'.format(temp, time, i+1)] = fit_result[i]\n",
    "#     else:\n",
    "#         exp_file['{}/{}/Peak_{}'.format(temp, time, i+1)] = fit_result[i]\n",
    "# exp_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
